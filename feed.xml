<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Richard Lucas&#39; Blog</title>
  <subtitle>Node.js and more...</subtitle>
  <link href="/feed.xml" rel="self"/>
  
  <link href="http://ralucas.github.io/"/>
  <updated>2018-01-08T02:36:31.458Z</updated>
  <id>http://ralucas.github.io/</id>
  
  <author>
    <name>Richard Lucas</name>
    <email>richard@richardalucas.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Activity Classification using MHI Techniques</title>
    <link href="http://ralucas.github.io/2017/12/03/Activity-Classification-using-MHI-Techniques/"/>
    <id>http://ralucas.github.io/2017/12/03/Activity-Classification-using-MHI-Techniques/</id>
    <published>2017-12-03T07:00:00.000Z</published>
    <updated>2018-01-08T02:36:31.458Z</updated>
    
    <content type="html"><![CDATA[<p><em>Activity classification by computers has a rich history and this paper seeks to describe, analyze, and compare some methods used in classifying a subset of actions. The creation of temporal templates via motion-energy images (MEI) and motion history images (MHI) were utilized to analyze and quantify frames of videos. Image moments were taken from the MHIs and a learning model was built. The results obtained are compared and discussed along with other comparative methods. The activities focused on were boxing, handclapping, handwaving, running, jogging, and walking.</em></p>
<h2 id="Interesting-Links"><a href="#Interesting-Links" class="headerlink" title="Interesting Links"></a>Interesting Links</h2><ul>
<li><strong>Multiple Activity Videos:</strong><ul>
<li>Handclapping &amp; Boxing Video <a href="https://youtu.be/dEtfgAYwCg4" target="_blank" rel="external">https://youtu.be/dEtfgAYwCg4</a></li>
<li>Multitude activity Video <a href="https://youtu.be/x_hFKZzc0jw" target="_blank" rel="external">https://youtu.be/x_hFKZzc0jw</a></li>
</ul>
</li>
</ul>
<h2 id="Related-work-in-recently-published-research"><a href="#Related-work-in-recently-published-research" class="headerlink" title="Related work in recently published research"></a>Related work in recently published research</h2><p>There are a number of research publications that are directly related to activity classification, although some of their methods may vary. The most pertinent related work to this project is that of Bobick and Davis [5], in which the idea of using temporal templates to classify activities is discussed. This technique relies primarily on the creation of Motion-energy images and Motion-history images to create a temporal template. Image moments are then extracted from these templates and a distance model is created.</p>
<p>An alternative to temporal templates is suggested in Schuldt, et al [8] in which the use of space-time features are used with a support vector machine classifier. The space-time features are, in essence, points of interest that occur at specific points over time allowing patterns to be developed. They are constructed through the use of image gradients and a Gaussian convolution kernel in which points of interest are located in comparison to a maxima. The use of SVMs in training a model are then taken to achieve fairly good results (and will be compared later herein).</p>
<p>In more recent work, the use of still poses and poselets (body part detection from joint and part positions) [7] to develop an underlying stick figure representation found good results in identifying activities. Additionally, this research took into account the 3D orientation from a trained model. The method achieved results of ~60% correct identification with just the poselet representation and ~65% when the object model was added. Another recent study [3] utilized summary dynamic rgb images and convolution neural network (CNN) to develop a system in which identification was done quickly and reasonably successfully as the researchers were able to get ~89% successful identification.</p>
<h2 id="Methodology-and-implementation-used"><a href="#Methodology-and-implementation-used" class="headerlink" title="Methodology and implementation used"></a>Methodology and implementation used</h2><p>Temporal templates were used to create modeled images over a period of time, traditional image moments [9][4][6][2] were then taken and a model was trained.</p>
<h3 id="Temporal-Templates"><a href="#Temporal-Templates" class="headerlink" title="Temporal Templates"></a>Temporal Templates</h3><p>Two types of temporal templates were created: motion-energy images (or binary images) (MEIs) and motion-history images (MHIs). In creating these images, each video frame was taken through a preprocessing step in order to better extract the purposeful, activity related motion from the background and tangential motions within each frame. This was done b first grayscaling each frame, then running the frame through OpenCV Gaussian blurring and morphing functions.</p>
<p>The MEIs were created by taking a temporal diff from each frame and assigning coordinates with a 0 or 1 given if the temporal difference was greater than a constant $\theta$ or not (see examples in figure 1). A $\theta$ of $14$ was used throughout the training and testing phases as it was determined to give the best results.</p>
<div style="display:flex;"><br><img align="left" width="160" height="120" src="/resources/A19C0C2A9DEED833992394DAB24C3EE7.png" alt="mei_image_boxing_person05_d3_10.png"><br><img align="right" alt="mei_image_handwaving_person01_d3_12.png" src="/resources/ADC2C3C9010B694FB9C870F47C89C5EF.png" width="160" height="120"><br></div><br><div style="display:flex;"><br><img align="left" width="160" height="120" src="/resources/206EF4CD0F290B8C44E39F800AAF6826.png" alt="mei_image_walking_person04_d3_20.png"><br><img align="right" width="160" height="120" src="/resources/889A6EB6627389DACAA15AFCB8DDBE01.png" alt="mei_image_handclapping_person05_d3_4.png"><br></div><br><div style="display:flex;"><br><img align="left" width="160" height="120" src="(/resources/58CCB63298A0D0C74797DC0B6133BE59.png" alt="![mei_image_jogging_person04_d3_0.png]"><br><img align="right" width="160" height="120" src="/resources/646C7B58F989519A1C2838B9718699DF.png" alt="mei_image_running_person05_d3_2.png"><br></div>

<p><strong>Figure 1</strong>: <em>Clockwise, starting in left corner: Boxing, Handwaving, Handclapping, Running, Jogging, Walking</em></p>
<p>The MHIs were built from those binary images and provide a more nuanced and graded view of the motion over time. These were calculated utilizing hand-crafted constants $\tau$, in which over time gradients were developed. Figure 2 shows an example of different people handwaving as it shows more of the change over time versus the constant that the MEIs show.</p>
<p>In creation of these temporal templates, the $\tau$ constant value for each activity was additionally used (Table 1) a demarcation for how many frames to analyze from a video, so the video sequences (as outlined in the sequences[1]) were divided further into small $\tau$ based chunks. This allowed for consistent training of an activity and expanding the total number of training samples, therefore giving more to the trained model to improve upon prediction.</p>
<table>
<thead>
<tr>
<th>Activity</th>
<th>Tau</th>
</tr>
</thead>
<tbody>
<tr>
<td>boxing</td>
<td>7</td>
</tr>
<tr>
<td>handclapping</td>
<td>13</td>
</tr>
<tr>
<td>handwaving</td>
<td>17</td>
</tr>
<tr>
<td>jogging</td>
<td>21</td>
</tr>
<tr>
<td>running</td>
<td>11</td>
</tr>
<tr>
<td>walking</td>
<td>35</td>
</tr>
</tbody>
</table>
<p><em>Table 1</em></p>
<div style="display:flex;"><br><img align="left" width="160" height="120" src="/resources/31DF5A4229040E941925BCAA6766B5A9.png" alt="mhi_image_boxing_person04_d3_3.png"><br><img align="right" width="160" height="120" src="/resources/A5627A0DA267394D6B3BE27EC2A0AB91.png" alt="mhi_image_handwaving_person05_d3_30.png"><br></div><br><div style="display:flex;"><br><img align="left" width="160" height="120" src="/resources/5DAB00468AFD541B0A7E0165381C3E02.png" alt="mhi_image_walking_person05_d3_7.png"><br><img align="right" width="160" height="120" src="/resources/F1E8F01CB2227A18975836934E58F422.png" alt="mhi_image_handclapping_person03_d3_6.png"><br></div><br><div style="display:flex;"><br><img align="left" width="160" height="120" src="/resources/E56FAD24DF1E1D637212375E26C0A87D.png" alt="mhi_image_jogging_person02_d3_7.png"><br><img align="right" width="160" height="120" src="/resources/70539DBC7EF87041DC08B733DFDD0242.png" alt="mhi_image_running_person05_d3_10.png"><br></div>

<p><strong>Figure 2:</strong> <em>Clockwise, starting in left corner: Boxing, Handwaving, Handclapping, Running, Jogging, Walking</em> </p>
<h3 id="Image-Moments"><a href="#Image-Moments" class="headerlink" title="Image Moments"></a>Image Moments</h3><p>Image moments for each MHI were taken to develop a feature set upon which the temporal templates could be compared. The central ($\mu$) and scale invariant ($\nu$) moments were calculated for the following moments $pq \in {20, 11, 02, 30, 21, 12, 03, 22}$ [4]. The 7 main Hu Moments [6][2] were then calculated from the scale invariant moments. However, after much testing and training, it was determined that the scale invariant moments gave the best results.</p>
<h3 id="Training-and-Prediction"><a href="#Training-and-Prediction" class="headerlink" title="Training and Prediction"></a>Training and Prediction</h3><p>A large dataset of videos [1] was used as input for training. The K-nearest neighbor algorithm was used to train, classify, and predict the videos. The K-nearest neighbor algorithm works by classifying input based on a plurality vote of nearest neighbors. The features used for training and prediction for this dataset was found to be a combination of the scale invariant features ($\nu$) and the Hu moments. The primary factor here was, in using the Hu moments as features, that enough differentiation was not provided and there was an increase in false positives when testing.</p>
<h2 id="Results-and-performance-statistics"><a href="#Results-and-performance-statistics" class="headerlink" title="Results and performance statistics"></a>Results and performance statistics</h2><p><em>Figure 3: Training results | 90.8% accuracy</em><br><img width="460" height="345" src="/resources/5EC509D8F11D712DBCE8FF4606A860E2.png" alt="training.png"></p>
<p><em>Figure 4: Test results | 84.1% accuracy</em><br><img width="460" height="345" src="/resources/64911BF7A62AE57DF347A9A11D123452.png" alt="test.png"></p>
<p>Figures 3 and 4 give a confusion matrix on the overall results from training and testing.</p>
<h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h3><p>In addition to the single activity videos used to train and test against, videos with multiple activities within the same video were run as an experiment (sample frames in Figure 6). The method used for each multiple activity video did the following:</p>
<p><em>Labels = Dictionary of labels $\rightarrow$ $\tau$ values</em> initialize<br><span>$Frame_List=1 + max(\tau)$</span></p>
<p>As outlined in Algorithm [dmap], multiple activity prediction, first gets an initial prediction by building an array of frames. Then as that frame list is iterated over and $mei$ and $mhi$ images are built, when the number of frames is equal to a $\tau$ value, a prediction from the predict engine is created based on the current $mhi$ values and that prediction is compared to the current $\tau$ label. If they are equal, then that label is returned and a $\tau$ number of frames is written and classified with that label.</p>
<h2 id="Analysis-of-results"><a href="#Analysis-of-results" class="headerlink" title="Analysis of results"></a>Analysis of results</h2><p>The six activities could be further categorized into two primary groups: stationary activities and moving activities. Given this, focus can be placed on results within these categories. The most glaring issue is that of the <em>handclapping</em> results. The trainer most commonly confused it with <em>handwaving</em> and <em>boxing</em>, which does have similar motions.</p>
<p>The moving activities also were difficult to separate, and particularly <em>running</em> and <em>jogging</em> proved to be quite difficult to distinguish between. However, given reasonably differentiated $\tau$ values, the variation was carried through. It could also be argued that the difference between jogging and running may be quite different from person to person, so I still believe that these two classifications are somewhat interchangeable.</p>
<h3 id="Analysis-of-experiment"><a href="#Analysis-of-experiment" class="headerlink" title="Analysis of experiment"></a>Analysis of experiment</h3><p>As shown in Table 2, the performance times of algorithm used in the experiment was fairly slow. It took close to half a second to complete a full run of the algorithm of frame set analysis and write, which entails running the algorithm (see above) and write the newly labeled frames to video.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Time (s)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Frames (36) analysis and prediction</td>
<td>0.45s</td>
</tr>
<tr>
<td>Moments calculation</td>
<td>0.013s</td>
</tr>
<tr>
<td>Temporal image creation</td>
<td>0.15s</td>
</tr>
</tbody>
</table>
<p><em>Table 2</em></p>
<p>The accuracy of the multiple activity videos was hit-or-miss. For example, in the video of just <em>handclapping</em> and <em>boxing</em>, the accuracy was outstanding, showing an above 90% accuracy (see Figure 5). However, in the multitude activity video, accuracy declined. Some of this was due to the definition of <em>jogging</em> versus <em>running</em>, but there were also misclassifications (see Figure 6). Throughout the multiple activity videos, there were misclassifications (see Figure 11), mostly among their two major groups (as discussed above), i.e. <em>walking</em> getting classified as <em>jogging</em>, <em>boxing</em> as <em>handclapping</em>, etc.</p>
<p><em>Figure 5: Handclapping and Boxing | 90.7% accuracy</em><br><img src="/resources/4E165FF834E416F58336EF37445CE402.png" alt="handclapping_boxing_matrix.png"><br><em>N.B. $nan$ means that label was not expected</em></p>
<p><em>Figure 6: Multitude | 36.4% accuracy</em><br><img src="/resources/2F9E7EA10E826520B4DB2FED7F3AEDAB.png" alt="multitude_matrix.png"><br><em>N.B. $nan$ means that label was not expected</em></p>
<div style="display:flex;"><br><img align="left" width="285" height="160" src="/resources/095BFCDDB5ACD1A9E10E6C8440C2341E.png" alt="experiment_1_160"><br><img align="right" width="285" height="160" src="/resources/5EC4CE79902E1C304DCE17A1B94331B7.png" alt="experiment_3_1232"><br></div><br><div style="display:flex;"><br><img align="left" width="285" height="160" src="/resources/89A45B61265B78D82C15B9CCBC5BD161.png" alt="experiment_2_1096"><br><img align="right" width="285" height="160" src="/resources/F101A2C26F3D379CA8E578F7C3D761C4.png" alt="experiment_2_524"><br></div><br><div style="display:flex;"><br><img align="left" width="285" height="160" src="/resources/A715ADD3B15BCD043840813FC32E721F.png" alt="experiment_3_468"><br><img align="right" width="285" height="160" src="/resources/FB3BA8C32C0C1DFFB7DD20B769DA7645.png" alt="experiment_1_1076"><br></div>

<p><strong>Figure 7:</strong> <em>Clockwise, starting in left corner: Boxing (correctly identified), Handwaving (incorrectly identified as clapping), Boxing (incorrectly identified as waving), Running (incorrectly identified as jogging), Walking (incorrectly identified as jogging), Handwaving (correctly identified</em></p>
<h3 id="Analysis-of-weaknesses"><a href="#Analysis-of-weaknesses" class="headerlink" title="Analysis of weaknesses"></a>Analysis of weaknesses</h3><p>There were some weaknesses that came to light in running these<br>predictions:</p>
<ul>
<li>Currently the method requires differing $\tau$ values or if they are similar, quite different $mhi$ images.</li>
<li>All the $\tau$ values were carefully set and vetted. Simply not a scalable process.</li>
<li>As the discussed above, the performance speed is quite slow.</li>
<li>Still a fairly custom and brittle development process.</li>
</ul>
<h2 id="Comparison-to-the-state-of-the-art-methods"><a href="#Comparison-to-the-state-of-the-art-methods" class="headerlink" title="Comparison to the state-of-the-art methods"></a>Comparison to the state-of-the-art methods</h2><p>In comparison of the methodology used to the state-of-the-art methods, we can look at the results obtained from usage of an identical dataset from the Schuldt, et al [8]. In comparing the confusion matrices from the Local SVM Approach to this one, the results obtained from the usage of MHI were quite better and more consistently accurate.</p>
<p><img src="/resources/1F9C0CCB9196C390E225FB74D38F5D0C.png" alt="svm_comp.png"></p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Accuracy</th>
</tr>
</thead>
<tbody>
<tr>
<td>  This paper</td>
<td>84.1%</td>
</tr>
<tr>
<td>  Bilen et al. [3]</td>
<td>89.1%</td>
</tr>
<tr>
<td>  Zha et al.</td>
<td>89.6%</td>
</tr>
<tr>
<td>  …others</td>
<td>~88.0%</td>
</tr>
</tbody>
</table>
<p><em>Table 3</em></p>
<h2 id="Proposals-for-improvement"><a href="#Proposals-for-improvement" class="headerlink" title="Proposals for improvement"></a>Proposals for improvement</h2><p>There are four proposals for improvement that I believe can improve the performance and success rate of predicting activities:</p>
<ul>
<li>Utilizing hidden markov models as a part of the prediction process, particularly in prediction of multiple activities. This would additionally require more training input.</li>
<li>Using poselets and stick figure representations as used in referenced work [7].</li>
<li>Building and utilizing convolutional neural networks, similar to the referenced work [3].</li>
<li>More and variegated training input videos.</li>
</ul>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] Action videos. <a href="http://www.nada.kth.se/cvap/actions/" target="_blank" rel="external">http://www.nada.kth.se/cvap/actions/</a>.<br>[2] Hu moments | opencv documentation. <https: docs.opencv.org="" 2.4="" modules="" imgproc="" doc="" structural="" analysis="" and="" shape="" descriptors.html?highlight="cvmatchshapes#humoments">. [Online; accessed 2-December-2017].<br>[3] H. Bilen, B. Fernando, E. Gavves, A. Vedaldi, and S. Gould. Dynamic image networks for action recognition. In 2016 <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pages 3034-3042, June 2016.<br>[4] A. F. Bobick. 8D-L2 activity recognition | CS6476 udacity lectures. <a href="https://classroom.udacity.com/courses/ud810/lessons/3513198914/concepts/34988000940923" target="_blank" rel="external">https://classroom.udacity.com/courses/ud810/lessons/3513198914/concepts/34988000940923</a>.<br>[5] A. F. Bobick and J. W. Davis. The recognition of human movement using temporal templates. <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 23(3):257-267, Mar 2001.<br>[6] Ming-Kuei Hu. Visual pattern recognition by moment invariants. <em>IRE Transactions on Information Theory</em>, 8(2):179-187, February 1962.<br>[7] S. Maji, L. Bourdev, and J. Malik. Action recognition from a distributed representation of pose and appearance. In <em>CVPR 2011</em>, pages 3177-3184, June 2011.<br>[8] C. Schuldt, I. Laptev, and B. Caputo. Recognizing human actions: a local svm approach. In <em>Proceedings of the 17th International Conference on Pattern Recognition, 2004. ICPR 2004., volume 3</em>, pages 32-36 Vol.3, Aug 2004.<br>[9] Wikipedia. Image moments | wikipedia, the free encyclopedia. <a href="https://en.wikipedia.org/w/index.php?title=LaTeX&amp;oldid=413720397" target="_blank" rel="external">https://en.wikipedia.org/w/index.php?title=LaTeX&amp;oldid=413720397</a>, 2017. [Online; accessed 2-December-2017].</https:></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;em&gt;Activity classification by computers has a rich history and this paper seeks to describe, analyze, and compare some methods used in c
    
    </summary>
    
    
      <category term="Activity Classification" scheme="http://ralucas.github.io/tags/Activity-Classification/"/>
    
      <category term="Computer Vision" scheme="http://ralucas.github.io/tags/Computer-Vision/"/>
    
  </entry>
  
  <entry>
    <title>Actor Model in Erlang</title>
    <link href="http://ralucas.github.io/2017/01/09/Actor-Model-in-Erlang/"/>
    <id>http://ralucas.github.io/2017/01/09/Actor-Model-in-Erlang/</id>
    <published>2017-01-09T08:13:46.000Z</published>
    <updated>2017-01-09T08:17:36.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Concurrency"><a href="#Concurrency" class="headerlink" title="Concurrency"></a>Concurrency</h3><p><em>Definition:</em> The ability of an executing program to run decomposed instructions in a parallelized fashion efficiently utilizing available resources.</p>
<p>From Joe Armstrong [10]:<br><img src="/resources/674F0D37FCA4FAC1BD2DF28A2B78E633.jpg" alt="con_and_par.jpg"></p>
<p>The way to phrase it, in my mind, is parallelism differs in that it is a purely physical difference, i.e. running the same program at the same time across similar devices, whereas concurrency infers running on the same machine (i.e. use of threads). But for the sake of this discussion, they may be used interchangeably</p>
<h3 id="Traditional-Concurrency"><a href="#Traditional-Concurrency" class="headerlink" title="Traditional Concurrency"></a>Traditional Concurrency</h3><p>Programming languages typically offer concurrent operation through the use of threads.  Given the lack of atomicity in the use of threads, locking primitives such as semaphores or mutexes are required. This can create difficult to program and debug situations, such as deadlock. For brevity, this survey assumes some knowledge of current concurrency models.</p>
<h3 id="Thinking-about-Parallelization"><a href="#Thinking-about-Parallelization" class="headerlink" title="Thinking about Parallelization"></a>Thinking about Parallelization</h3><p>Obviously, computing speeds have continued their march to the beat of Moore’s Law, and given the complexity in writing concurrent programs that take advantage of the processors and architectures at the time, it’s not always worth it to consider writing software in this way. But there’s speculation that we may begin to see the perhaps potential physical limitations: there’s only so many transistors you can continue to fit into ever smaller physical areas.  </p>
<p>So, the use of parallelization becomes more and more attractive.  Amdahl’s Law basically gives a good rule of thumb for how parallelized a program can get [My definition]:</p>
<blockquote>
<p>A program is only parallelizable in terms of it’s slowest part.</p>
</blockquote>
<p><img src="/resources/B7F87CBB6DDA25AE976B6382BFE40BF6.png" alt="AmdahlsLaw.svg.png"></p>
<h2 id="Actor-Model"><a href="#Actor-Model" class="headerlink" title="Actor Model"></a>Actor Model</h2><p>Actors are a concurrency primitive that do not share resources with another actor. They share state/data via message passing.</p>
<p>An actor is an entity that has a mailbox and a behavior. It takes a message and can then send messages to other actors, create new actors, and return another actor describing its next behavior.</p>
<blockquote>
<p>Concurrency in actors is constrained only by the availability of hardware resources and by the logical-dependence inherent in the computation. - Gul Agha [1]</p>
</blockquote>
<p>The actor model is a framework to think about, model, and build distributed concurrent systems.</p>
<h3 id="Quick-History"><a href="#Quick-History" class="headerlink" title="Quick History"></a>Quick History</h3><p>The Actor Model was first proposed by Carl Hewitt in 1973 (yeah, the actor model is fully entrenched in middle age :))  It was further solidified over many years by a number of other computer scientists and by Gul Agha in his disseration on the Actor Model in 1985 [1].</p>
<h3 id="Important-Concepts"><a href="#Important-Concepts" class="headerlink" title="Important Concepts"></a>Important Concepts</h3><ol>
<li>No shared state between actors</li>
<li>Functions asynchronously</li>
<li>All about message passing for communication<ol>
<li>Only way to share/change state is through this message passing</li>
</ol>
</li>
</ol>
<h3 id="Enter-Erlang…"><a href="#Enter-Erlang…" class="headerlink" title="Enter Erlang…"></a>Enter Erlang…</h3><p>The actor model is inherent to Erlang and is built into the language and somewhat fundamental to understanding the distributed nature of Erlang. </p>
<p>One thing to note, is Erlang was designed for the telephony industry, so some of the driving ideals such as <em>reliability</em> demanded that Erlang utilize a model that didn’t incur potential for data loss, that is possible in the more traditional concurrency models discussed above.</p>
<blockquote>
<p>An Erlang program describes a series of functions. Each function uses pattern matching to determine which function to execute.[6]</p>
</blockquote>
<p>In Erlang, each thread of execution is a lightweight process.[4] </p>
<p>Erlang utilizes pattern matching to process messages.</p>
<blockquote>
<p>The Erlang view of the world is that everything is a process and that processes can interact only by exchanging messages. - Joe Armstrong [7]</p>
</blockquote>
<h4 id="Creating-a-process"><a href="#Creating-a-process" class="headerlink" title="Creating a process"></a>Creating a process</h4><p>To create a process in Erlang, just call <code>spawn</code>, which will return a process id (pid) (refer to the Erlang docs for the signature of <code>spawn</code> you want).  Here, the example uses <code>spawn/3</code> (<code>spawn(Module, Function, Args) -&gt; pid()</code>) [5]<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">-module(actor_file).</div><div class="line">...</div><div class="line">start() -&gt; </div><div class="line">  spawn(actor_file, run, []).</div></pre></td></tr></table></figure></p>
<p>Calling <code>start/0</code> here returns the pid:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">1&gt; c(actor_file).</div><div class="line">2&gt; Pid = actor_file:start().</div><div class="line">3&gt; Pid.</div><div class="line">&lt;0.80.0&gt;</div></pre></td></tr></table></figure></p>
<p>But it’s not a process in the OS definition. It’s an Erlang process, so it runs in the Erlang VM. It runs in user space, not bound to the kernel, so is scheduled by the Erlang Scheduler. </p>
<p>And it’s a lightweight process…how lightweight: </p>
<blockquote>
<p>A newly spawned Erlang process uses 309 words of memory [4] </p>
</blockquote>
<p>From the Erlang docs on memory:</p>
<blockquote>
<p>The unit of measurement is memory words. There exists both a 32-bit and a 64-bit implementation. A word is therefore 4 bytes or 8 bytes, respectively. [6]</p>
</blockquote>
<p>In fact, let’s check how much memory our process(es) are using:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&#123;_,Bytes&#125; = process_info(actor_file:start(), memory).</div><div class="line">  &#123;memory,2720&#125;</div></pre></td></tr></table></figure></p>
<p>And they are very quick to spawn…from Joe Armstrong:</p>
<blockquote>
<p>Spawning 20,000 processes took an average of 3.0 microseconds/process of CPU time and 3.4 microseconds of elapsed (wall-clock) time.</p>
</blockquote>
<h3 id="How-Erlang-schedules-a-process"><a href="#How-Erlang-schedules-a-process" class="headerlink" title="How Erlang schedules a process"></a>How Erlang schedules a process</h3><p>Erlang uses a preemptive scheduler. A preemptive scheduler works by running tasks, preempting, then resuming them based on a specific metric, such as priority, time or reduction.  Many other async languages, such as Node.js and Python’s Twisted, utilize cooperative scheduling, which requires tasks to release themselves voluntarily.</p>
<p>Erlang’s preemptive scheduler uses a reduction count. A reduction is typically a function call, garbage collection, message sending, etc. The reduction count for an Erlang process is 2000, which can go quite quickly.</p>
<p>Additionally, processes do and can be flagged with priorities: ‘max’, ‘high’, ‘normal’, and ‘low’.</p>
<p>The scheduler makes Erlang a great choice for low-latency, parallelized programs as it can manage multi-tasking efficiently, given that it doesn’t allow any one process to monopolize resources.</p>
<h3 id="References-and-Further-Reading"><a href="#References-and-Further-Reading" class="headerlink" title="References and Further Reading"></a>References and Further Reading</h3><p>[1] Agha, Gul, <em>Actors: A Model of Concurrent Computation in Distributed Systems</em>, <a href="http://www.cypherpunks.to/erights/history/actors/AITR-844.pdf" target="_blank" rel="external">http://www.cypherpunks.to/erights/history/actors/AITR-844.pdf</a>, 1985.<br>[2] Vermeersch, Ruben, <em>Concurrency in Erlang &amp; Scala: The Actor Model</em> <a href="https://rocketeer.be/articles/concurrency-in-erlang-scala" target="_blank" rel="external">https://rocketeer.be/articles/concurrency-in-erlang-scala</a>, 2009.<br>[3] Hebert, Fred, The Hitchhiker’s Guide to Concurrency, <em>Learn You Some Erlang: for great good!</em>, <a href="http://learnyousomeerlang.com/the-hitchhikers-guide-to-concurrency" target="_blank" rel="external">http://learnyousomeerlang.com/the-hitchhikers-guide-to-concurrency</a>, 2013.<br>[4] Erlang/OTP System Documentation, <a href="http://erlang.org/doc/index.html" target="_blank" rel="external">http://erlang.org/doc/index.html</a>, 2016<br>[5] <a href="http://erlang.org/doc/reference_manual/processes.html" target="_blank" rel="external">http://erlang.org/doc/reference_manual/processes.html</a><br>[6] <a href="http://erlang.org/doc/efficiency_guide/advanced.html" target="_blank" rel="external">http://erlang.org/doc/efficiency_guide/advanced.html</a><br>[7] Armstrong, Joe. <em>Programming Erlang: Software for a Concurrent World</em>, 2nd Ed, 2013.<br>[8] Tate, Bruce. <em>Crossing borders: Concurrent programming with Erlang</em>, <a href="http://www.ibm.com/developerworks/java/library/j-cb04186/j-cb04186-pdf.pdf" target="_blank" rel="external">http://www.ibm.com/developerworks/java/library/j-cb04186/j-cb04186-pdf.pdf</a>, 2006.<br>[9] <a href="https://hamidreza-s.github.io/erlang/scheduling/real-time/preemptive/migration/2016/02/09/erlang-scheduler-details.html" target="_blank" rel="external">https://hamidreza-s.github.io/erlang/scheduling/real-time/preemptive/migration/2016/02/09/erlang-scheduler-details.html</a><br>[10] <a href="http://joearms.github.io/2013/04/05/concurrent-and-parallel-programming.html" target="_blank" rel="external">http://joearms.github.io/2013/04/05/concurrent-and-parallel-programming.html</a><br>[11] <a href="http://yosefk.com/blog/parallelism-and-concurrency-need-different-tools.html" target="_blank" rel="external">http://yosefk.com/blog/parallelism-and-concurrency-need-different-tools.html</a><br>[12]  Andersen, Jesper Louis&gt; <em>How Erlang does scheduling</em>, <a href="http://jlouisramblings.blogspot.co.uk/2013/01/how-erlang-does-scheduling.html" target="_blank" rel="external">http://jlouisramblings.blogspot.co.uk/2013/01/how-erlang-does-scheduling.html</a>, 2013.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Concurrency&quot;&gt;&lt;a href=&quot;#Concurrency&quot; class=&quot;headerlink&quot; title=&quot;Concurrency&quot;&gt;&lt;/a&gt;Concurrency&lt;/h3&gt;&lt;p&gt;&lt;em&gt;Definition:&lt;/em&gt; The ability o
    
    </summary>
    
    
      <category term="Erlang" scheme="http://ralucas.github.io/tags/Erlang/"/>
    
      <category term="Actor Model" scheme="http://ralucas.github.io/tags/Actor-Model/"/>
    
      <category term="Concurrency" scheme="http://ralucas.github.io/tags/Concurrency/"/>
    
      <category term="Distributed Computing" scheme="http://ralucas.github.io/tags/Distributed-Computing/"/>
    
  </entry>
  
  <entry>
    <title>Writing a small socket server in C</title>
    <link href="http://ralucas.github.io/2016/08/11/Writing-a-small-socket-server-in-C/"/>
    <id>http://ralucas.github.io/2016/08/11/Writing-a-small-socket-server-in-C/</id>
    <published>2016-08-12T05:15:22.000Z</published>
    <updated>2016-08-12T05:27:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>Building a socket server in C is a great introduction to the language as well as IPC mechanisms such as sockets and it can show you how simple it is to set up a server.  For this installment, we’re going to do a single-threaded version.</p>
<p>So, let’s get started…</p>
<h3 id="The-Server"><a href="#The-Server" class="headerlink" title="The Server"></a>The Server</h3><p>First I want to define some constants that we’ll use throughout. For some of these you may want to pass these in dynamically, but for this case I’m just hardcoding them here as constants:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">#define SOCKET_ERROR  -1</div><div class="line"></div><div class="line">#define MAX_PENDING_CONNECTIONS   10</div><div class="line">#define LOCALHOST   &quot;127.0.0.1&quot;</div><div class="line">#define PORT        8080</div><div class="line">#define BUFSIZE     1024</div></pre></td></tr></table></figure>
<p>We’ll put the server in a void function that we’ll call serve: <code>void serve()</code>, so<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">void serve() &#123;</div><div class="line">  // Put all subsequent code here</div></pre></td></tr></table></figure></p>
<p>Create the server socket file descriptor, usually created with with <code>PF_INET</code>, <code>SOCK_STREAM</code>, and with tcp <code>IPPROTO_TCP</code>.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">int server_socket_fd;</div><div class="line">if ( (server_socket_fd = socket(PF_INET, SOCK_STREAM, IPPROTO_TCP)) &lt;= SOCKET_ERROR ) &#123;</div><div class="line">  perror(&quot;Error creating the server socket&quot;);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Set the socket options, passing in the newly created socket file descriptor.  Additionally, </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">int sockopt;</div><div class="line">int socket_opts;</div><div class="line">if ( (socket_opts = setsockopt(server_socket_fd, SOL_SOCKET, SO_REUSEADDR, &amp;sockopt, sizeof(int))) &lt;= SOCKET_ERROR ) &#123;</div><div class="line">  perror(&quot;Error setting the socket options&quot;);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Now we need to set up the socket address:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">// Create ip address</div><div class="line">in_addr_t ip_address;</div><div class="line">ip_address = inet_addr();</div><div class="line"></div><div class="line">struct sockaddr_in socket_address;</div><div class="line">// Allocate some memory for the socket_address</div><div class="line">memset(&amp;socket_address, 0, sizeof(socket_address));</div><div class="line">socket_address.sin_family = AF_INET;</div><div class="line">socket_address.sin_addr.s_addr = ip_address;</div><div class="line">socket_address.sin_port = htons(PORT);</div></pre></td></tr></table></figure>
<p>Bind the server</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">int server;</div><div class="line">if ( (server = bind(server_socket_fd, (struct sockaddr *) &amp;socket_address, sizeof(socket_address))) &lt;= SOCKET_ERROR ) &#123;</div><div class="line">  perror(&quot;Error binding the server&quot;);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Listen for incoming connections</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">int connection_listener;</div><div class="line">if ( (connection_listener = listen(server_socket_fd, MAX_PENDING_CONNECTIONS)) &lt;= SOCKET_ERROR ) &#123;</div><div class="line">  perror(&quot;Error connecting the listener&quot;);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Now let’s run the server by running an infinite loop</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">for (;;) &#123;</div><div class="line">  int client;</div><div class="line">  struct sockaddr_in client_address;</div><div class="line">  socklen_t client_len;</div><div class="line">  </div><div class="line">  client_len = sizeof(client_address);</div><div class="line">  </div><div class="line">  // Accept incoming connections from the client</div><div class="line">  if ( (client = accept(server_socket_fd, (struct sockaddr *) &amp;client_address, &amp;client_len)) &lt;= SOCKET_ERROR ) &#123;</div><div class="line">    perror(&quot;Error accepting on the server socket&quot;);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  // Receive the message</div><div class="line">  int receiver;</div><div class="line">  if ( (receiver = recv(client, buffer, BUFSIZE - 1, 0)) &lt;= SOCKET_ERROR ) &#123;</div><div class="line">    perror(&quot;Error receiving message from the client);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  // Respond</div><div class="line">  ssize_t sender;</div><div class="line">  char response[BUFSIZE];</div><div class="line">  size_t len;</div><div class="line">  </div><div class="line">  strcpy(response, &quot;This is a response string!&quot;);</div><div class="line">  len = strlen(response);</div><div class="line">  </div><div class="line">  if ( (sender = send(client, response, len, 0)) &lt;= SOCKET_ERROR ) &#123;</div><div class="line">    perror(&quot;Error sending the response&quot;);</div><div class="line">  &#125;</div><div class="line">  fprintf(stdout, &quot;Successfully sent (%i) message&quot;, sender);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Go ahead, build it, and fire it up and send a curl request.  In a future post, I’ll build an HTTP server.</p>
<p>The source code for this can be found here: <a href="https://github.com/ralucas/basic_c_socket_server" target="_blank" rel="external">https://github.com/ralucas/basic_c_socket_server</a></p>
<p>I also suggest taking a look at <a href="http://beej.us/guide/bgnet/output/html/singlepage/bgnet.html" target="_blank" rel="external">Beej’s Guide to Networking</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Building a socket server in C is a great introduction to the language as well as IPC mechanisms such as sockets and it can show you how s
    
    </summary>
    
    
      <category term="sockets" scheme="http://ralucas.github.io/tags/sockets/"/>
    
      <category term="C" scheme="http://ralucas.github.io/tags/C/"/>
    
      <category term="sys/socket.h" scheme="http://ralucas.github.io/tags/sys-socket-h/"/>
    
  </entry>
  
  <entry>
    <title>Understanding PortLand</title>
    <link href="http://ralucas.github.io/2016/04/28/Understanding-PortLand/"/>
    <id>http://ralucas.github.io/2016/04/28/Understanding-PortLand/</id>
    <published>2016-04-28T06:00:00.000Z</published>
    <updated>2016-05-04T03:31:44.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="What-is-PortLand"><a href="#What-is-PortLand" class="headerlink" title="What is PortLand"></a>What is PortLand</h3><p>Today, most web applications are hosted in the “cloud”, which is in turn hosted in huge datacenters located in various places all over the world. Modern datacenters today suffer from a few limitations including: lack of scalability, difficult management, inflexible communication, and limited support for virtual machine migration.[1] PortLand is a proposal that attempted to solve some of these limitations. And what PortLand proposes is a solution to mitigate these issues by delivering scalable layer 2 routing, forwarding, and addressing for large data center networks.  Portland utilizes the three tier fat-tree topology of edge hosts connected to aggreggation hosts which are connected to core hosts (Figure 1).</p>
<p><img src="/resources/0463E74CD6E2574BA0BAB3B1BBA7F63E.png" alt="fat-tree-topology.png"></p>
<h3 id="Why-Layer-2"><a href="#Why-Layer-2" class="headerlink" title="Why Layer 2"></a>Why Layer 2</h3><p>In large data centers, certain requirements come into being:</p>
<ul>
<li>Easy VM migration</li>
<li>Need for less active administration and configuration</li>
<li>Efficient end-host to end-host communication</li>
<li>No forwarding loops</li>
<li>Rapid and efficient failure detection</li>
</ul>
<p>Layer 3, IP, doesn’t enable easy VM migration as migration requires that VM’s change their IP addresses.  Additionally, configuration of a Layer 3 data center is onerous given that it requires each switch to be configured and DHCP servers to be synchronized.  Layer 2, while not the silver bullet, is still more able to satisfy these requirements under the Portland scenario.</p>
<p>Portland is able to solve these issues through the use of Pseudo MAC addresses, controlled by a centralized mechanism (Fabric Manager), enabling efficient, loop-free forwarding with little necessary state management. </p>
<h3 id="Fabric-Manager"><a href="#Fabric-Manager" class="headerlink" title="Fabric Manager"></a>Fabric Manager</h3><p>The <em>fabric manager</em> is a centralized (user) process running on a dedicated machine that maintains a soft state about the network configuration.  These responsibilities include information about the topology, assisting with ARP resolution, fault tolerance, and multicast. The use of <em>soft state</em> is important here as it eliminates the need for active administration and replication is simpler as state does not need to be replicated as well.</p>
<h4 id="What-the-Fabric-Manager-FM-Does"><a href="#What-the-Fabric-Manager-FM-Does" class="headerlink" title="What the Fabric Manager (FM) Does"></a>What the Fabric Manager (FM) Does</h4><p>The fabric manager reduces broadcast overhead in the common ARP request cases. So, when an edge switch intercepts a ARP request for IP to MAC mapping, it forwards the request onto the fabric manager, and the FM checks the PMAC table (see below), if the entry is there, it gives the PMAC back to the edge switch which creates the ARP reply and sends it to the original host.</p>
<p><strong>VM Migration</strong><br>Additionally, when doing VM migration, the VM will send out an ARP with it’s new IP to MAC mapping, which gets forwarded to the FM.  The FM, in an effort to invalidate any cache that hosts may have regarding the newly migrated VM, sends out an invalidation message to the migrated VM’s previous switch.</p>
<p><strong>Location</strong><br>The fabric manager is located in the logical center of the data center. It can also be located</p>
<h3 id="Pseudo-MAC-Addresses"><a href="#Pseudo-MAC-Addresses" class="headerlink" title="Pseudo MAC Addresses"></a>Pseudo MAC Addresses</h3><p>In order to efficiently forward and route as well as easily migrate VMs, Portland utilizes the concept of heirarchical Pseudo MAC Addresses (PMACs). Each end host in the data center gets a PMAC and in turn the PMAC encodes the location of the host in the DC topology.</p>
<h4 id="Components-of-PMAC"><a href="#Components-of-PMAC" class="headerlink" title="Components of PMAC"></a>Components of PMAC</h4><p>The 48-bit PMAC is composed of 4 parts in the form of <code>[pod].[position].[port].[vmid]</code>, so:</p>
<ul>
<li>Pod (16bits): The pod number of the edge switch</li>
<li>Position (8bits): Hosts position in the pod</li>
<li>Port (8bits): Switch-local view of the port number the host is connected to</li>
<li>VMID (16bits): Used to multiplex multiple VMs on the physical box.</li>
</ul>
<p>This constructed PMAC (<code>[pod].[position].[port].[vmid]</code>) is then entered into the switch’s local PMAC table that is mapped to the hosts Actual MAC address (AMAC) and IP address.  This mapping then is propogated to the Fabric Manager and it uses it to respond to ARP requests.  Additionally, the switch creates a flow table entry to rewrite PMAC destination address to the AMAC for traffic headed to that host.</p>
<h4 id="Why-PMAC-is-useful"><a href="#Why-PMAC-is-useful" class="headerlink" title="Why PMAC is useful"></a>Why PMAC is useful</h4><blockquote>
<p>PMAC addresses enable efficient, provably loop-free forwarding with small switch state.</p>
</blockquote>
<p>Given that traditional layer 2 based centers have scalability and efficiency issues due to the need to support broadcast (usually via ARP).  It also requires that switches maintain large MAC forwarding tables that can have 100,000 to millions of entries, requiring memory and software that just isn’t practical in today’s switch hardware landscape.</p>
<h3 id="Location-Discovery-Protocol"><a href="#Location-Discovery-Protocol" class="headerlink" title="Location Discovery Protocol"></a>Location Discovery Protocol</h3><p>The <em>Location Discovery Protocol</em> (LDP) is used in the assignment of the PMAC. LDP in turn, utilizes a messaging system called Location Discovery Message (LDM), that gets periodically sent by switches in the system out on all of their ports. This protocol enables loop free propogation of packets by ensuring that packets travel down the topology and not back up.</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>Portland is a data center network fabric that utilizes PMACs, a Fabric Manager, and a Location Discovery Protocol as the core components for improving data handling in large scale data centers.  This design improves on forwarding table sizes, which when layer 2 mapped, can contain 100,000 or more entries</p>
<p>[1] Mysore, Pamboris, Farrington, Huang, Miri, Radhakrishnan, Subramanya, and Vahdat. 2009. <a href="http://www.sigcomm.org/ccr/papers/2009/October/1594977.1592575" target="_blank" rel="external"><em>PortLand: A Scalable Fault-Tolerant Layer 2 Data Center Network Fabric</em></a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;What-is-PortLand&quot;&gt;&lt;a href=&quot;#What-is-PortLand&quot; class=&quot;headerlink&quot; title=&quot;What is PortLand&quot;&gt;&lt;/a&gt;What is PortLand&lt;/h3&gt;&lt;p&gt;Today, most we
    
    </summary>
    
    
      <category term="Data centers" scheme="http://ralucas.github.io/tags/Data-centers/"/>
    
      <category term="Networking" scheme="http://ralucas.github.io/tags/Networking/"/>
    
      <category term="PortLand" scheme="http://ralucas.github.io/tags/PortLand/"/>
    
      <category term="Ethernet" scheme="http://ralucas.github.io/tags/Ethernet/"/>
    
  </entry>
  
  <entry>
    <title>Securing Internet Routing</title>
    <link href="http://ralucas.github.io/2016/04/23/Securing-Internet-Routing/"/>
    <id>http://ralucas.github.io/2016/04/23/Securing-Internet-Routing/</id>
    <published>2016-04-23T06:00:00.000Z</published>
    <updated>2016-04-23T16:57:33.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Border-Gateway-Protocol-BGP"><a href="#Border-Gateway-Protocol-BGP" class="headerlink" title="Border Gateway Protocol (BGP)"></a>Border Gateway Protocol (BGP)</h3><p>BGP, an important piece of the larger Internet’s architecture, is a protocol that enables the setting up of routing and exchange of reachability information between large networks (Autonomous Systems). It’s the protocol used to develop routes between these Autonomous Systems (ASes), routing to destinations via IP prefixes. BGP makes announcements that the ASes use to discover routes to these IP prefixes. </p>
<p>BGP is important to the business of the Internet, advertising routes, routing based on business relationships. ASes usually make sure that it’s in their “best” interest before routing traffic and there is a rule-of-thumb that seems to be generally followed:</p>
<blockquote>
<p>An AS will advertise a route to a neighboring AS if:</p>
<ol>
<li>The neighbor is a customer, or</li>
<li>The route is for a prefix originated by the advertising AS, or</li>
<li>The route is through a customer of the advertising AS</li>
</ol>
</blockquote>
<p>BGP was originally introduced, like many of the protocols in use in the Internet, in the early days, when the Internet was more innocent.  So, issues with security persist surrounding the protocol.</p>
<h3 id="BGP-Security-Risks"><a href="#BGP-Security-Risks" class="headerlink" title="BGP Security Risks"></a>BGP Security Risks</h3><h4 id="Hijacks"><a href="#Hijacks" class="headerlink" title="Hijacks"></a>Hijacks</h4><p>BGP doesn’t have in place any mechanism to properly authenticate allocations of IP prefixes to ASes, so as a result entire IP prefix blocks can be hijacked fairly easily, either accidently or purposefully.  There are two main types of hijacks: Prefix and subprefix.</p>
<p><em>Prefix:</em><br>The hijacker AS originates and announces the <em>exact same</em> prefix as a legitimate AS that has the IP allocation.  The announcement gets propogated through the system and other ASes begin chosing their routes for that IP prefix and some will chose to go through the bogus AS, others won’t, given route length.</p>
<p><em>Subprefix:</em><br>The hijacker AS can potentially intercept 100% of the network traffic.  Here the hijacker originates a prefix that is covered by the victim IP prefix.  BGP uses longest-prefix match (LPM), so if a hijacker were to advertise a prefix that was LPM, then traffic would redirect to the hijacker AS.</p>
<h4 id="Route-Leaks"><a href="#Route-Leaks" class="headerlink" title="Route Leaks"></a>Route Leaks</h4><p>This isn’t a bogus route, but instead the leaker announces a legitimate route, but does it to too many of its neighbors.  So, then the leaker is overwhelmed by traffic from its neighbors that are now utilizing the leaked route. This can be disastrous if the leaker is not designed to handle high levels of traffic.</p>
<h4 id="Path-Shortening-Attack"><a href="#Path-Shortening-Attack" class="headerlink" title="Path-Shortening Attack"></a>Path-Shortening Attack</h4><p>An attacker announces a short bogus path to a prefix that terminates at an authorized origin AS.</p>
<h4 id="Protocol-downgrade-attack"><a href="#Protocol-downgrade-attack" class="headerlink" title="Protocol downgrade attack"></a>Protocol downgrade attack</h4><p>ASes that have, for instance, deployed BGPSEC can be convinced by an attacker to select a bogus path instead of the secured route because it’s cheaper.</p>
<h4 id="Incident-Impact"><a href="#Incident-Impact" class="headerlink" title="Incident Impact"></a>Incident Impact</h4><p><em>Blackhole:</em><br>Network traffic stops at the perpetrator AS and goes no further.</p>
<p><em>Interception:</em><br>Perpetrator AS invisibly intercepts traffic and the traffic also continues onto it’s intended destination.</p>
<h3 id="BGP-Defense-Mechanisms"><a href="#BGP-Defense-Mechanisms" class="headerlink" title="BGP Defense Mechanisms"></a>BGP Defense Mechanisms</h3><h4 id="Prefix-filtering"><a href="#Prefix-filtering" class="headerlink" title="Prefix filtering"></a>Prefix filtering</h4><p>A whitelisting technique used to filter out bad BGP announcements. It works by using the AS rule-of-thumb and keeping a prefix list of IP prefixes of customers and ignoring any announcement from a customer not on the list. This defense has been used since the 1990s. </p>
<p><em>Upsides:</em></p>
<ul>
<li>It is simple and effective mechanism and if all ASes deployed it, a large portion of routing leaks and hijacks would be prevented.</li>
</ul>
<p><em>Downsides:</em></p>
<ul>
<li>The downside is that it only works on customer leaks. </li>
<li>ASes also aren’t necessarily incentivized to deploy this filtering outside of good Internet citzenship.</li>
</ul>
<h4 id="RPKI"><a href="#RPKI" class="headerlink" title="RPKI"></a>RPKI</h4><p>Resource Public Key Infrastructure (RPKI) is another defense method that provides a trusted mapping from allocated IP prefixes to BGP authorized ASes for origination.  It creates a cryptographic hierarchy of authorities, which is rooted at the regional Internet registries (i.e. ARIN, RIPE, AfriNIC, etc.). The holder of the certificate for a prefix can then sign an authorization allowing a prefix to be originated via BGP.</p>
<p><em>Upsides:</em></p>
<ul>
<li>Does not require any modification to current BGP message formats</li>
<li>Cryptography can be performed offline</li>
<li>As opposed to Prefix Filtering, it doesn’t tie itself to potential political/business conflict of interests as it can be used to filter BGP announcements made by any neighbor.</li>
</ul>
<p><em>Downsides:</em></p>
<ul>
<li>Potential for abuse of the RPKI, i.e. RPKI being attacked, misconfigured, or abused in some other way in which trust is lost in the protocol.</li>
<li>Cannot prevent route leaking attacks as it’s purpose is to prevent unauthorized messages, whereas route leaks come from authorized origins.</li>
<li>Cannot prevent path-shortening attack as the origin is legitimate and shortest path takes precedence.</li>
</ul>
<h4 id="BGPSEC"><a href="#BGPSEC" class="headerlink" title="BGPSEC"></a>BGPSEC</h4><p>BGPSEC, currently in standardization process by the IETF, builds on RPKI, adding crypto signatures to BCP messages.  Each AS must sign a BGP message upon announcement. The signature includes the prefix and AS-level path, the AS number of the AS receiving the message, and all the previous signed messages received from previous ASes on the path.</p>
<p><em>Upsides:</em></p>
<ul>
<li>No path-shortening attacks are possible because a shortened path would not pass the signature checks required as the origin would be checked against neighbor signatures.</li>
</ul>
<p><em>Downsides:</em></p>
<ul>
<li>Unlike RPKI, BGPSEC is online crypto as routers sign and verify the BGP messages.  This has a higher computational load, requiring the routers to be designed and built with that in mind.</li>
<li>To gain the full benefits of BGPSEC, every AS needs to deploy it. This requires that the already decentralized ASes, who have their own political and business objectives, to agree to use this protocol.<ul>
<li>To remedy this, one way is to gain traction via early adoption by some of the ASes</li>
</ul>
</li>
<li>ASes tend to prioritize economic demands over those of security demands and given that BGPSEC only provides some small benefits over RPKI, ASes are not as incentivized.</li>
<li>Suffers from protocol downgrade attacks.</li>
</ul>
<p>[1] Goldberg, 2014. <a href="http://queue.acm.org/detail.cfm?id=2668966" target="_blank" rel="external"><em>Why is it taking so long to secure internet routing</em></a> </p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Border-Gateway-Protocol-BGP&quot;&gt;&lt;a href=&quot;#Border-Gateway-Protocol-BGP&quot; class=&quot;headerlink&quot; title=&quot;Border Gateway Protocol (BGP)&quot;&gt;&lt;/a&gt;Bor
    
    </summary>
    
    
      <category term="Networking" scheme="http://ralucas.github.io/tags/Networking/"/>
    
      <category term="BGP" scheme="http://ralucas.github.io/tags/BGP/"/>
    
      <category term="Security" scheme="http://ralucas.github.io/tags/Security/"/>
    
      <category term="Routing" scheme="http://ralucas.github.io/tags/Routing/"/>
    
  </entry>
  
  <entry>
    <title>Jellyfish Data Center Topology Review</title>
    <link href="http://ralucas.github.io/2016/04/22/Jellyfish-Data-Center-Topology-Review/"/>
    <id>http://ralucas.github.io/2016/04/22/Jellyfish-Data-Center-Topology-Review/</id>
    <published>2016-04-22T06:00:00.000Z</published>
    <updated>2016-04-27T09:02:57.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="What-is-Jellyfish"><a href="#What-is-Jellyfish" class="headerlink" title="What is Jellyfish?"></a>What is Jellyfish?</h3><p>Jellyfish, an <em>incrementally-expandable</em>, high-bandwidth data center networking topology based on randomness.</p>
<blockquote>
<p>Definition: a degree-bounded random graph topology among top-of-rack switches.</p>
</blockquote>
<p>Basically, it’s an unstructured network that utilizes a randomized topology for interconnection in a data center, unlike, for example a fat tree topology that utilizes hierarchies (Figure 1). It allows for construction of arbitrary-size networks that can be easily incrementally expanded as needs arise in the data center for capacity or bandwidth.</p>
<p><img src="/resources/0463E74CD6E2574BA0BAB3B1BBA7F63E.png" alt="fat-tree-topology.png"></p>
<h3 id="Jellyfish-challenges"><a href="#Jellyfish-challenges" class="headerlink" title="Jellyfish challenges"></a>Jellyfish challenges</h3><p>As a result of an unstructured data center network, challenges arise:</p>
<ol>
<li>Routing</li>
<li>Physical construction</li>
<li>Cabling layout</li>
</ol>
<h3 id="How-it’s-constructed"><a href="#How-it’s-constructed" class="headerlink" title="How it’s constructed"></a>How it’s constructed</h3><p>Using the assumption that every switch has the same number of ports and servers, then with <code>N</code> racks, the network supports <code>N(k - r)</code> servers, where <code>k</code> is the number of ports and <code>r</code> is the number of ports used to connect to other racks. So, <code>k - r</code> is the number of ports that can be used to connect to servers. </p>
<p>To wire this up, just pick a random pair of switches with free ports and link them and continue to do this process until all links are exhausted.</p>
<h3 id="Key-Path-Length"><a href="#Key-Path-Length" class="headerlink" title="Key: Path Length"></a>Key: Path Length</h3><p>According to the authors, the end-to-end throughput of a data center’s topology (how fast does data flow through it) isn’t solely dependent on the capacity (bandwidth/speed) of the network.  Another important metric is the amount of network capacity that’s consumed in delivering each byte.  This is represented in <em>average path length</em>. In order to deliver each byte of data, a network takes a series of hops in delivering that data.  The less hops, the lower the average path length, the less network capacity consumed, therefore the faster the data can flow.  Jellyfish has a lower average path length than standard hierarchal models.</p>
<p><img src="/resources/DF1265ED7860D94F42585069B49DA6A0.png" alt="jellyfish_path_comparison.png"> (a) Fat-tree path lengths (b) Jellyfish path lengths</p>
<h3 id="Key-Flexibility-and-Expansion"><a href="#Key-Flexibility-and-Expansion" class="headerlink" title="Key: Flexibility and Expansion"></a>Key: Flexibility and Expansion</h3><p>Jellyfish’s construction is such that incrementally adding even just one server rack or switch is quite simple.  The only rewiring necessary is limited to the number of ports being added. Additionally, Jellyfish allows for expansion using newer equipment that may have higher port-counts.  </p>
<p><em>One note here:</em> Expansion may not produce uniform-random graph. However, topologies built incrementally versus those built from scratch show similar capacity throughputs and path lengths.</p>
<h3 id="Key-Resilience"><a href="#Key-Resilience" class="headerlink" title="Key: Resilience"></a>Key: Resilience</h3><p>Jellyfish, in the face of failures, still maintains it’s structure.  Additionally, Jellyfish, in comparison with a fat-tree topology with less servers, supports the same capacity, path-length, and resilience.</p>
<h4 id="Cabling"><a href="#Cabling" class="headerlink" title="Cabling"></a>Cabling</h4><p>In Jellyfish, there are more than twice as many cables running between switches than from servers to switches, so placing all the switches closely together makes sense.  It’s suggested that the switch-cluster, where the majority of cables congregate, be placed in the center of the data center, with aggregate cable bundles running to each server-rack.  Space should be left in the middle for additional switches and then more servers will just be added to the outside.</p>
<p>In massive data centers, Jellyfish can be adapted with all of the pluses that it offers over fat-tree.</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>Jellyfish, a random graph based network topology, is a scalable topology for data centers that makes setup and expandability simple. Jellyfish, also, can support 25% more servers than fat-tree, has on-average shorter path-length, is highly failure resilient, and shows network capacity of better than 90% of other known topologies.</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;What-is-Jellyfish&quot;&gt;&lt;a href=&quot;#What-is-Jellyfish&quot; class=&quot;headerlink&quot; title=&quot;What is Jellyfish?&quot;&gt;&lt;/a&gt;What is Jellyfish?&lt;/h3&gt;&lt;p&gt;Jellyfis
    
    </summary>
    
    
      <category term="Jellyfish" scheme="http://ralucas.github.io/tags/Jellyfish/"/>
    
      <category term="Data centers" scheme="http://ralucas.github.io/tags/Data-centers/"/>
    
      <category term="Scaling" scheme="http://ralucas.github.io/tags/Scaling/"/>
    
      <category term="Networking" scheme="http://ralucas.github.io/tags/Networking/"/>
    
  </entry>
  
  <entry>
    <title>Understanding DASH (Dynamic Adaptive Streaming over HTTP)</title>
    <link href="http://ralucas.github.io/2016/04/20/Understanding-Dynamic-Adaptive-Streaming-over-HTTP/"/>
    <id>http://ralucas.github.io/2016/04/20/Understanding-Dynamic-Adaptive-Streaming-over-HTTP/</id>
    <published>2016-04-20T06:00:00.000Z</published>
    <updated>2016-04-20T07:08:08.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="What-is-DASH-comparatively"><a href="#What-is-DASH-comparatively" class="headerlink" title="What is DASH, comparatively?"></a>What is DASH, comparatively?</h3><p>Dynamic Adaptive Streaming over HTTP (DASH) is a standard that intends to address weaknesses in RTSP and progressive download methods currently used in streaming content over the internet.  </p>
<h4 id="RTSP"><a href="#RTSP" class="headerlink" title="RTSP"></a>RTSP</h4><p>RTSP is a streaming protocol that manages a stateful connection with the client, tracking the state through the client interation.  </p>
<h4 id="Progressive"><a href="#Progressive" class="headerlink" title="Progressive"></a>Progressive</h4><p>Progressive download can utilize HTTP and uses byte range requests to respond to the client.  The issues with progressive are that it’s not bitrate responsive, bandwidth can potentially be wasted if the user switches their request, and doesn’t do live media. Despite these weakeness, progressive download enjoys wide adoption</p>
<h3 id="Why-use-HTTP"><a href="#Why-use-HTTP" class="headerlink" title="Why use HTTP?"></a>Why use HTTP?</h3><p>Content Delivery Networks (CDNs) have proliferated all over the world and given this, their scale, and their reliability, using them to manage streaming services just makes sense and…they use HTTP.  Here are the nine reason’s Mr. Stockhammer gives [1] (my paraphrasing):</p>
<ol>
<li>HTTP Streaming is spreading widely as a form of delivery of Internet Video</li>
<li>Trend towards HTTP as the main protocol for media delivery over the Internet</li>
<li>Given the wide deployment of HTTP along with the TCP/IP stack, it probides reliabiliy and easy deployment</li>
<li>HTTP avoids NAT and firewall traversal issues as it doesn’t require a dedicated connection…it’s stateless</li>
<li>Allows delivery mechanisms and common methods such as CDNs, HTTP Caches, and HTTP Servers to be used, which already exist in profligate</li>
<li>Moves control of the HTTP session to the client</li>
<li>Provides the ability of the client to choose content rate given bandwidth as opposed to having the streaming server negotiate that</li>
<li>Allows content rate to be seamlessly changed on the fly given changes in bandwidth</li>
<li>Has the potential to accelerate fixed-mobile convergence.</li>
</ol>
<h3 id="DASH-Goals"><a href="#DASH-Goals" class="headerlink" title="DASH Goals"></a>DASH Goals</h3><p>The DASH solution is intended to:</p>
<ol>
<li>support delivery of media in ISO base media file formats</li>
<li>stay out of presentation logic</li>
<li>permit integration of different presentation frameworks</li>
</ol>
<p>The protocol then in turn intends to define:</p>
<ol>
<li>Media Presentation as a stuctured collection of data</li>
<li>Formats of Segments, an integral data unit of a Media Presentation, that can be HTTP URI addressable</li>
<li>Delivery protocol of Segment, i.e. HTTP/1.1</li>
<li>A how-to for the client to utitlize the above information to establish a streaming service</li>
</ol>
<p>It supports features:</p>
<ol>
<li>Fast initial startup and seeking</li>
<li>bandwidth efficiency</li>
<li>adaptive bitrate switching</li>
<li>adaption to CDN properties</li>
<li>reuse of HTTP-servers and caches</li>
<li>reuse of existing media playout engines</li>
<li>Support for on-demand, live play</li>
<li>Simplicity</li>
</ol>
<h3 id="Overall"><a href="#Overall" class="headerlink" title="Overall"></a>Overall</h3><p>DASH is a media streaming protocol that seeks to improve upon some of the known issues with RTSP and progressive download, while taking advantage of an already common and well-supported application protocol, HTTP.  It was intended to be easily adapted to existing infrastructure, particularly the usage of HTTP CDNs.  It’s intended to be generic enough so that it’s independent of media format.  It’s main features are it’s adaptatability to changing network bandwidth, existing HTTP infrastructure, media formats, and flexibility to client presentations.</p>
<p>[1] Stockhammer, 2011. <a href="https://www.w3.org/2010/11/web-and-tv/papers/webtv2_submission_64.pdf" target="_blank" rel="external">Dynamic Adaptive Streaming over HTTP - Design Principles and Standards</a><br>[2] <a href="http://www.cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking-index-vni/mobile-white-paper-c11-520862.html" target="_blank" rel="external">Cisco Visual Networking Index: Global Mobile Data Traffic Forecast Update, 2015–2020 White Paper</a>, February 2016</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;What-is-DASH-comparatively&quot;&gt;&lt;a href=&quot;#What-is-DASH-comparatively&quot; class=&quot;headerlink&quot; title=&quot;What is DASH, comparatively?&quot;&gt;&lt;/a&gt;What i
    
    </summary>
    
    
      <category term="Networking" scheme="http://ralucas.github.io/tags/Networking/"/>
    
      <category term="HTTP" scheme="http://ralucas.github.io/tags/HTTP/"/>
    
      <category term="DASH" scheme="http://ralucas.github.io/tags/DASH/"/>
    
      <category term="Streaming" scheme="http://ralucas.github.io/tags/Streaming/"/>
    
  </entry>
  
  <entry>
    <title>Understanding Controlling Queue Delay and CoDel</title>
    <link href="http://ralucas.github.io/2016/04/19/Understanding-Controlling-Queue-Delay/"/>
    <id>http://ralucas.github.io/2016/04/19/Understanding-Controlling-Queue-Delay/</id>
    <published>2016-04-19T06:00:00.000Z</published>
    <updated>2016-04-20T04:25:28.000Z</updated>
    
    <content type="html"><![CDATA[<p>This is a survey of the “Controlling Queue Delaty” academic paper by Kathleen Nichols and Van Jacobson from ACMQueue in 2012.[1]</p>
<h3 id="Bufferbloat-is-still-a-problem"><a href="#Bufferbloat-is-still-a-problem" class="headerlink" title="Bufferbloat is still a problem!"></a>Bufferbloat is still a problem!</h3><p>Packet-based networks use buffers to handle short-term fluctuation in traffic flow. Bufferbloat describes the standing packet queue that’s created when there is a mismatch between the senders maximum send rate (window size) and the bottleneck’s pipe size. This issue of bufferbloat has been known for many decades now. </p>
<p>And given all the streaming today, it’s an important issue as applications today are much more delay-sensitive.</p>
<h3 id="The-Standing-Queue"><a href="#The-Standing-Queue" class="headerlink" title="The Standing Queue"></a>The Standing Queue</h3><p>This standing queue is the result from this mismatch. Because it creates delays and doesn’t improve throughput, it gets seen as a congestion issue and not properly seen in the light of queue or traffic theory.  This is due to theorists seeing TCP’s reliable and highly correlated process, in which the packet arrival rate equals the departure rate, as improbable.</p>
<h3 id="Not-an-easy-problem"><a href="#Not-an-easy-problem" class="headerlink" title="Not an easy problem"></a>Not an easy problem</h3><p>And the problem has been difficult to solve. Given that senders set the window size, queues begin to build up at the bottlenecks.  This, thereby, makes it difficult for senders to adjust their sending rate given the constantly changing with conditions (flows coming and going, physical conditions, etc.) that occur in the bandwidth of the bottlenecks.</p>
<h3 id="Reliable-Detection-is-Hard"><a href="#Reliable-Detection-is-Hard" class="headerlink" title="Reliable Detection is Hard"></a>Reliable Detection is Hard</h3><p>A large queue is necessary to get started as the buffer needs to initially fill, so queue size really doesn’t give us much information about excess queue.</p>
<blockquote>
<p>A good queue is occupancy that goes away in about one RTT; bad queue persists for several RTTs [1]</p>
</blockquote>
<h3 id="Active-Queue-Management-AQM"><a href="#Active-Queue-Management-AQM" class="headerlink" title="Active Queue Management (AQM)"></a>Active Queue Management (AQM)</h3><p>Active Queue Management is the solution for this bufferbloat problem, but it’s lack of widespread adoption has emanated from implementation difficulties and misunderstanding in the overall issue.</p>
<h5 id="AQM-Goals"><a href="#AQM-Goals" class="headerlink" title="AQM Goals"></a>AQM Goals</h5><ol>
<li>Paramaterless - no implementation needed</li>
<li>Treats good and bad queue differently</li>
<li>Controls delay</li>
<li>Adapts to dynamically changing link rates</li>
<li>Simple and efficient - from home to enterprise use</li>
</ol>
<h3 id="CoDel-A-proposed-solution"><a href="#CoDel-A-proposed-solution" class="headerlink" title="CoDel: A proposed solution"></a>CoDel: A proposed solution</h3><p>CoDel (Contolled Delay Management) is a proposed piece to that solution to this issue of queue management.  It makes three main innovations to it’s algorithm:</p>
<ol>
<li>Using the local minimum queue to measure standing queue and not based on any of the previously used metrics such as the average size, etc.</li>
<li>Keeping a single-state variable measuring how long the minimum have above or below the target for standing queue rather than a window of values to compute the minimum.</li>
<li>Using the packet-sojourn time through the queue as the unit of measure as opposed to bytes or packets.</li>
</ol>
<h3 id="Why-the-minimum-value"><a href="#Why-the-minimum-value" class="headerlink" title="Why the minimum value?"></a>Why the minimum value?</h3><p>The minimum packet sojourn can be decreased only when a packet is dequeued, so CoDel can go to work when packets are dequeued for sending and no locks are needed in the software. If the buffer is full on arrival, then a packet is dropped.</p>
<h3 id="The-target-and-interval"><a href="#The-target-and-interval" class="headerlink" title="The target and interval"></a>The <code>target</code> and <code>interval</code></h3><p>The <code>target</code> represents the “acceptable standing queue delay.”  Very importantly, it’s measured in packet-sojourn time, <strong>not</strong> bytes or packets. Additionally, it’s unacceptable to drop packets if there are fewer than one MTU of bytes in the buffer.<br>The <code>interval</code> represents “a time on the order of a worst-case RTT of connections through the bottleneck.”  </p>
<h3 id="Let’s-put-it-together"><a href="#Let’s-put-it-together" class="headerlink" title="Let’s put it together"></a>Let’s put it together</h3><p>So, the crux here is that when the queue delay (it’s packet-sojourn time) is more than the <code>target</code> for at least <code>interval</code> time, then a packet is dropped and it’s not until the queue delay gets itself back below <code>target</code> that it stops dropping packets. In it’s dropping mode, it’s ‘next drop time’ is decreased each time as <code>1/SqRt(total_number_of_drops)</code> with the intention of getting a linear change in throughput (TCP flow rate).</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>CoDel looks to be the best way to attack queue delay. While not the silver bullet for queue delay, it satisfies the five goals it set out. Manufacturers still need to build and market devices with proper buffer management. </p>
<h4 id="Further-Reading"><a href="#Further-Reading" class="headerlink" title="Further Reading"></a>Further Reading</h4><p><a href="http://tools.ietf.org/pdf/draft-nichols-tsvwg-codel-02.pdf" target="_blank" rel="external">CoDel IETF Draft</a><br><a href="http://www.bufferbloat.net/projects/codel/wiki/Wiki/" target="_blank" rel="external">CoDel Wiki</a></p>
<p>[1] Nichols and Jacobsen, 2012. <a href="http://queue.acm.org/detail.cfm?id=2209336" target="_blank" rel="external">Controlling Queue Delay</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This is a survey of the “Controlling Queue Delaty” academic paper by Kathleen Nichols and Van Jacobson from ACMQueue in 2012.[1]&lt;/p&gt;
&lt;h3 
    
    </summary>
    
    
      <category term="Networking" scheme="http://ralucas.github.io/tags/Networking/"/>
    
      <category term="TCP" scheme="http://ralucas.github.io/tags/TCP/"/>
    
      <category term="Router buffers" scheme="http://ralucas.github.io/tags/Router-buffers/"/>
    
      <category term="Bufferbloat" scheme="http://ralucas.github.io/tags/Bufferbloat/"/>
    
      <category term="CoDel" scheme="http://ralucas.github.io/tags/CoDel/"/>
    
      <category term="Queue delay" scheme="http://ralucas.github.io/tags/Queue-delay/"/>
    
  </entry>
  
  <entry>
    <title>Understanding Sizing Router Buffers</title>
    <link href="http://ralucas.github.io/2016/04/17/Understanding-Sizing-Router-Buffers/"/>
    <id>http://ralucas.github.io/2016/04/17/Understanding-Sizing-Router-Buffers/</id>
    <published>2016-04-17T06:00:00.000Z</published>
    <updated>2016-04-20T04:22:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>This is a survey of the “Sizing Routing Buffers” academic paper by Appenzeller, Keslassy, and McKeown published in 2004.</p>
<p>In the past, Internet routers had buffers that used a rule-of-thumb using the equation of: <code>B = RTT X C</code>.  Where <code>RTT</code> is the round-trip time of a packet and <code>C</code> is the data rate.  This rule-of-thumb is no longer useful.  The primary goal of the rule-of-thumb, or any for that matter, is to keep a link as close to 100% utilization as possible, as this maximizes the throughput of the network.</p>
<h3 id="Why-is-it-no-longer-useful"><a href="#Why-is-it-no-longer-useful" class="headerlink" title="Why is it no longer useful?"></a>Why is it no longer useful?</h3><blockquote>
<ol>
<li><p>Large buffers are difficult to manufacture, given that they must use slow, off-chip DRAM for memory buffering. DRAM (dynamic RAM) has some problems.  It has an access time of about 50ns, whereas a packet of size 40bytes, can arrive and depart in 8ns: DRAM is <em>slow</em> and slows network speed down.  Additionally, they require utilization of a wide DRAM bus, which requires a large number of data pins, which in turn increases the power consumption of the DRAM boards.</p>
</li>
<li><p>Large buffers can contribute to lengthening queueing delays which can in turn cause problems with congestion control algorithms, as they rely on packet loss in order to inform them of TCP congestion.</p>
</li>
<li><p>The original rule-of-thumb came from a 1994 paper and experiments that used a small number of multiplexed flows (up to 8) on a now comparatively low-speed connection of only 40 Mb/s.  Today, for example, typical backbone links are now beginning to operate at 100 Gb/s or greater[2] with many thousand multiplexed flows.</p>
</li>
</ol>
</blockquote>
<p>Some consider router buffers to be one of the largest contributors to network traffic speed uncertainty.</p>
<h3 id="Why-is-Overbuffering-bad"><a href="#Why-is-Overbuffering-bad" class="headerlink" title="Why is Overbuffering bad?"></a>Why is Overbuffering bad?</h3><blockquote>
<ol>
<li>In order to accomodate large buffers, routers have to be designed accordingly, leading to larger power consumption, more board space, and lower density.</li>
<li>It increases delay when congestion occurs and conflict with low-latency real-time applications like video games.  And in some cases, make applications completely unusable.</li>
</ol>
</blockquote>
<p>One of the main issues with the idea that a buffer should be utilized to maximize the network throughput is that it doesn’t take into account TCP Congestion Control algorithms that rely on a packet loss to indicate congestion and to go into action. TCP will always make the buffer overflow in order to lead to packet loss.</p>
<h3 id="Single-flow-and-Synchronized-flows"><a href="#Single-flow-and-Synchronized-flows" class="headerlink" title="Single-flow and Synchronized flows"></a>Single-flow and Synchronized flows</h3><p>According to the paper, “the key to sizing the buffer is to make sure that the buffer is large enough, so that while the sender pauses, the buffer doesn’t go empty.” In the case of the single, long-lived flow and synchronized TCP flows, for the buffer to never go empty it needs to be half of the window size max. This is because of how TCP performs.  When it TCP sees packet loss, it goes into AIMD congestion control mode and drops it’s packet flow by half. So, while the buffer almost hits zero, it never quite does.</p>
<h3 id="Desynchronized-flows"><a href="#Desynchronized-flows" class="headerlink" title="Desynchronized flows"></a>Desynchronized flows</h3><p>Most internet backbones handle enough simultaneous flows, i.e. greater than 500, that they usually operate under a desynchronized flow pattern. In this environment, the TCP sawtooth isn’t synched, so the more flows that are added, the window size from peak to trough is smoothed out and gets smaller.  So, given that as discussed before, that the amount of buffer needed to maintain the network utilization was half of the window max size, then if the window size is now smaller, then <em>therefore</em> the buffer size can be even smaller.</p>
<p>Also, in this case, the flow length distribution is heavily distributed towards long flows, as they typically take up 80% of the bandwidth.  However, most of the flows are in fact from short-lived flows (fewer than 100 packets). But, they only account for about 20% of the bandwidth.  This is partly due because short flows usually don’t get out of TCP slow-start mode and never fully utilize the network bandwidth, whereas long flows typically get into congestion control mode, maximizing the network bandwidth.</p>
<h3 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h3><p>Through this survey, it is apparent that smaller buffer sizes are imperative for best network bandwidth utilization no matter the type of flow or flow environment.  Smaller buffers increase bandwidth utilization because they 1) signal to the TCP flow when to go into congestion mode sooner, 2) larger buffers can lead to delay, and 3) are cheaper to manufacture.</p>
<p>[1] Appenzaller, Keslassy, McKeown, 2004. <a href="http://guido.appenzeller.net/pubs/sigcomm.pdf" target="_blank" rel="external"><em>Sizing Routing Buffers</em></a><br>[2] Malik, 2013. <a href="https://gigaom.com/2013/08/16/100g-200g-400g-internets-core-is-getting-fatter-to-meet-our-tech-planets-bandwidth-demand/" target="_blank" rel="external"><em>100G, 200G, 400G: Internet’s core is getting fatter to meet our tech planet’s bandwidth demand</em></a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This is a survey of the “Sizing Routing Buffers” academic paper by Appenzeller, Keslassy, and McKeown published in 2004.&lt;/p&gt;
&lt;p&gt;In the pa
    
    </summary>
    
    
      <category term="Networking" scheme="http://ralucas.github.io/tags/Networking/"/>
    
      <category term="TCP" scheme="http://ralucas.github.io/tags/TCP/"/>
    
      <category term="Router buffers" scheme="http://ralucas.github.io/tags/Router-buffers/"/>
    
  </entry>
  
  <entry>
    <title>Useful CLI commands</title>
    <link href="http://ralucas.github.io/2015/08/14/Useful-CLI-Commands/"/>
    <id>http://ralucas.github.io/2015/08/14/Useful-CLI-Commands/</id>
    <published>2015-08-15T03:37:59.000Z</published>
    <updated>2016-04-27T13:41:11.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Some-CLI-Commands-that-I’ve-found-useful"><a href="#Some-CLI-Commands-that-I’ve-found-useful" class="headerlink" title="Some CLI Commands that I’ve found useful:"></a>Some CLI Commands that I’ve found useful:</h2><h4 id="Viewing-processes-and-killing-them"><a href="#Viewing-processes-and-killing-them" class="headerlink" title="Viewing processes and killing them"></a>Viewing processes and killing them</h4><p><code>$ lsof -Pi | grep LISTEN</code></p>
<ul>
<li>Displays processes running and ports</li>
<li>The PID is the second number (2nd column from left)</li>
</ul>
<p><code>$ kill -9 $PID</code></p>
<ul>
<li>This kills the process at the entered PID with extreme prejudice</li>
</ul>
<h4 id="Using-find"><a href="#Using-find" class="headerlink" title="Using find"></a>Using find</h4><p><code>$ find . -name &#39;*.css&#39;</code></p>
<ul>
<li>This will recurse all directories and list all CSS files (and directories ending with “.css”) under the current directory (represented by “.”)</li>
</ul>
<p><code>$ find . -type f -name &#39;*.css&#39;</code></p>
<ul>
<li>This will only match CSS files (case-sensitively)</li>
</ul>
<p><code>$ find . -name &quot;*.css&quot; -exec grep -l &quot;#content&quot; {} \;</code></p>
<ul>
<li>This example finds all CSS files that do something with your HTML ID #content</li>
</ul>
<p><code>$ find . -mtime -1 -type f</code></p>
<ul>
<li>find files changed in the last 1 day</li>
</ul>
<p><code>$ find . \! -path &quot;*CVS*&quot; -type f -name &quot;*.css&quot;</code></p>
<ul>
<li>find CSS files, omitting results containing “CVS”</li>
</ul>
<p><code>$ find ~/src -newer main.css</code></p>
<ul>
<li>find files newer than main.css in ~/src</li>
</ul>
<p><code>$ find . -name \*.css -print0 | xargs -0 grep -nH foo</code></p>
<ul>
<li>combine with xargs for more power than -exec</li>
</ul>
<h4 id="Deleting-a-folder-and-it’s-contents"><a href="#Deleting-a-folder-and-it’s-contents" class="headerlink" title="Deleting a folder and it’s contents"></a>Deleting a folder and it’s contents</h4><p><em>Please use carefully</em></p>
<p><code>$ rm -rf [folder_name]</code></p>
<ul>
<li>Always include a folder name</li>
</ul>
<h4 id="Copying-a-folder-and-contents"><a href="#Copying-a-folder-and-contents" class="headerlink" title="Copying a folder and contents"></a>Copying a folder and contents</h4><p><code>$ cp -avr /from/folder /to/new_folder</code></p>
<ul>
<li>-a : Preserve the specified attributes such as directory an file mode, ownership, timestamps, if possible additional attributes: context, links, xattr, all.</li>
<li>-v : Explain what is being done (verbose).</li>
<li>-r : Copy directories recursively.</li>
</ul>
<h4 id="What-is-grep"><a href="#What-is-grep" class="headerlink" title="What is grep"></a>What is grep</h4><ul>
<li>It is a command that finds text/strings inside of files</li>
<li><p>It can take regular expressions</p>
</li>
<li><p>recurse through a directory</p>
</li>
</ul>
<p><code>$ grep -r &#39;lookforthisexpression&#39; files/*</code></p>
<ul>
<li>case insensitive search</li>
</ul>
<p><code>$ grep -i &#39;anycaseterm&#39; file.txt</code></p>
<h4 id="Make-a-file-…for-testing…"><a href="#Make-a-file-…for-testing…" class="headerlink" title="Make a file (…for testing…)"></a>Make a file (…for testing…)</h4><ul>
<li>mkfile command</li>
<li>input number, then size (i.e. k for kb or g for gb), then filename</li>
</ul>
<p><code>$ mkfile -n [size][b|k|m|g] [filename]</code></p>
<h4 id="Heroku-commands"><a href="#Heroku-commands" class="headerlink" title="Heroku commands"></a>Heroku commands</h4><ul>
<li>Get to the console/bash on the remote server</li>
</ul>
<p><code>$ heroku run bash --app [put_app_name_here]</code></p>
<h4 id="Compiling-bash-scripts"><a href="#Compiling-bash-scripts" class="headerlink" title="Compiling bash scripts"></a>Compiling bash scripts</h4><p><code>$ chmod +x ./[bash_script.sh]</code></p>
<h4 id="Redirect-to-port-80-on-linux-server"><a href="#Redirect-to-port-80-on-linux-server" class="headerlink" title="Redirect to port 80 on linux server"></a>Redirect to port 80 on linux server</h4><p><code>$ sudo iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j REDIRECT --to-port 3000</code></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Some-CLI-Commands-that-I’ve-found-useful&quot;&gt;&lt;a href=&quot;#Some-CLI-Commands-that-I’ve-found-useful&quot; class=&quot;headerlink&quot; title=&quot;Some CLI Com
    
    </summary>
    
    
      <category term="CLI" scheme="http://ralucas.github.io/tags/CLI/"/>
    
      <category term="Linux" scheme="http://ralucas.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Resizing image with imagemagick</title>
    <link href="http://ralucas.github.io/2015/08/11/Resizing-image-with-imagemagick/"/>
    <id>http://ralucas.github.io/2015/08/11/Resizing-image-with-imagemagick/</id>
    <published>2015-08-12T03:46:31.000Z</published>
    <updated>2015-08-12T03:46:31.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="Quick-one-liner"><a href="#Quick-one-liner" class="headerlink" title="Quick one-liner"></a>Quick one-liner</h4><p>Using imagemagick to resize an image, keep it’s proportion (i.e. 4 x 3 ), and place it in the middle with a white background:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">convert input.png -resize 1280x800 -background white -gravity center -extent 1280x800 output.png</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;Quick-one-liner&quot;&gt;&lt;a href=&quot;#Quick-one-liner&quot; class=&quot;headerlink&quot; title=&quot;Quick one-liner&quot;&gt;&lt;/a&gt;Quick one-liner&lt;/h4&gt;&lt;p&gt;Using imagemagick 
    
    </summary>
    
    
      <category term="imagemagick" scheme="http://ralucas.github.io/tags/imagemagick/"/>
    
      <category term="resizing images" scheme="http://ralucas.github.io/tags/resizing-images/"/>
    
  </entry>
  
  <entry>
    <title>Mocking out the Request module in Node.js for Testing</title>
    <link href="http://ralucas.github.io/2015/08/10/Mocking-out-the-request-module-for-testing/"/>
    <id>http://ralucas.github.io/2015/08/10/Mocking-out-the-request-module-for-testing/</id>
    <published>2015-08-11T05:09:26.000Z</published>
    <updated>2015-08-11T05:09:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>So, recently I needed to write a test that required that I mock the request module out as I wanted to pass a specific error code back to the response handler and do something different with it.  In this case, I wanted to retry the request.</p>
<p>I first attacked the issue with Sinon.js library.  If you’ve ever tested in javascript, sinon.js is an indispensable mocking and spying library.</p>
<p>So, I wrote:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">...</div><div class="line">var request = require(&apos;request&apos;),</div><div class="line">...</div><div class="line">before(done) &#123;</div><div class="line">  stub = sinon.stub(request)</div><div class="line">    .withArgs(&#123;</div><div class="line">      method: &apos;GET&apos;,</div><div class="line">      url: &apos;http://example.com&apos;</div><div class="line">    &#125;);</div><div class="line">  done();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>However, that doesn’t work as sinon.js requires if you’re stubbing out a module for there to be method that you use, i.e. <code>stub = sinon.stub(request, &#39;get&#39;)</code> … <a href="http://stackoverflow.com/questions/27462799/sinon-how-to-stub-nested-function" target="_blank" rel="external">see this StackOverflow issue</a></p>
<p>The problem was that the api that I was testing had already largely been written and I didn’t now want to rewrite a bunch of it just to make it testable for this one case.  So, enter <a href="https://github.com/mfncooper/mockery" target="_blank" rel="external">Mockery</a>.</p>
<p>Mockery is great in this instance, but be careful when you use it as it tears down the <code>require</code> statement, so use it as tightly as you can and tear it down immediately after use.  So, I separated out my test:</p>
<p>myModule.js:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">...</div><div class="line">var request = require(&apos;request&apos;);</div><div class="line">...</div><div class="line">function handler(callback) &#123;</div><div class="line">  return function(err, res, body) &#123;</div><div class="line">    if (err) &#123;</div><div class="line">      //doStuff</div><div class="line">    &#125;</div><div class="line">    ...//doOtherStuff</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">exports.getSomeStuff = function(url, callback) &#123;</div><div class="line">  return request(&#123;</div><div class="line">    method: &apos;GET&apos;,</div><div class="line">    url: url</div><div class="line">  &#125;, handler(callback));</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>test.js:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line">...</div><div class="line">var request = require(&apos;request&apos;);</div><div class="line">...</div><div class="line"> describe(&apos;request error testing&apos;, function() &#123;</div><div class="line">    var stub, module;</div><div class="line">    </div><div class="line">    before(function(done) &#123;</div><div class="line">      mockery.enable(&#123;</div><div class="line">        warnOnReplace: false,</div><div class="line">        warnOnUnregistered: false,</div><div class="line">        useCleanCache: true</div><div class="line">      &#125;);</div><div class="line"></div><div class="line">      stub = sinon.stub();</div><div class="line"></div><div class="line">      mockery.registerMock(&apos;request&apos;, stub);</div><div class="line"></div><div class="line">      mm = require(&apos;./myModule&apos;);</div><div class="line"></div><div class="line">      done();</div><div class="line">    &#125;);</div><div class="line"></div><div class="line">    after(function(done) &#123;</div><div class="line">      mockery.disable();</div><div class="line">      done();</div><div class="line">    &#125;);</div><div class="line"></div><div class="line">    it(&apos;should retry once on ETIMEDOUT error&apos;, function(done) &#123;</div><div class="line"> </div><div class="line">      var spy = sinon.spy(client, &apos;request&apos;);</div><div class="line"></div><div class="line">      var err = new Error(&apos;connect ETIMEDOUT&apos;);</div><div class="line"></div><div class="line">      stub.yields(err, null, null);</div><div class="line"></div><div class="line">      mm.getSomeStuff(&apos;http://example.com&apos;, function(err, json) &#123;</div><div class="line">        expect(spy.calledOnce).to.be.true;</div><div class="line">        expect(stub.calledTwice).to.be.true;</div><div class="line">        expect(err.message).to.include(&apos;ETIMEDOUT&apos;);</div><div class="line">        done();</div><div class="line">      &#125;);</div><div class="line"></div><div class="line">    &#125;);</div><div class="line">  &#125;);</div></pre></td></tr></table></figure>
<p>So, there you have it. Comment if you have any thoughts or questions.</p>
<p>Another really great post that helped me: <a href="http://bulkan-evcimen.com/using_mockery_to_mock_modules_nodejs.html" target="_blank" rel="external">http://bulkan-evcimen.com/using_mockery_to_mock_modules_nodejs.html</a></p>
<p>Cheers!</p>
<p>Richard</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;So, recently I needed to write a test that required that I mock the request module out as I wanted to pass a specific error code back to 
    
    </summary>
    
    
      <category term="Testing" scheme="http://ralucas.github.io/tags/Testing/"/>
    
      <category term="Node.js" scheme="http://ralucas.github.io/tags/Node-js/"/>
    
      <category term="Request" scheme="http://ralucas.github.io/tags/Request/"/>
    
      <category term="Mockery" scheme="http://ralucas.github.io/tags/Mockery/"/>
    
      <category term="Sinon.js" scheme="http://ralucas.github.io/tags/Sinon-js/"/>
    
  </entry>
  
  <entry>
    <title>Importing CSV in Postgres</title>
    <link href="http://ralucas.github.io/2013/12/10/Importing-CSV-in-Postgres/"/>
    <id>http://ralucas.github.io/2013/12/10/Importing-CSV-in-Postgres/</id>
    <published>2013-12-11T01:19:18.000Z</published>
    <updated>2015-02-02T01:19:50.000Z</updated>
    
    <content type="html"><![CDATA[<p>Log into the database from the terminal:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ psql database_name</div></pre></td></tr></table></figure></p>
<p>Create a new table:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"># CREATE TABLE table_name(column_name data_type, column_name2 data_type, etc);</div><div class="line"></div><div class="line">example:</div><div class="line"></div><div class="line"># CREATE TABLE trips(block_id int,route_id </div><div class="line">text,direction_id int,trip_headsign text,shape_id text,service_id text,trip_id text);</div><div class="line"></div><div class="line">//And then you should see:</div><div class="line">CREATE TABLE</div></pre></td></tr></table></figure></p>
<p>Copy the data from a CSV:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># COPY table_name FROM &apos;/path/to/CSV_file.txt&apos; DELIMITER &apos;,&apos; CSV;</div><div class="line"></div><div class="line">example:</div><div class="line"></div><div class="line"># COPY trips FROM &apos;/home/username/Downloads/data/trips.txt&apos; DELIMITER &apos;,&apos; CSV;</div><div class="line"></div><div class="line">//And then you should see:</div><div class="line">COPY XXXX &lt;-number of lines</div></pre></td></tr></table></figure></p>
<p>View the tables and select the table you wish to view:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># \dt</div><div class="line"># SELECT * FROM table_name;</div></pre></td></tr></table></figure></p>
<p>Cheers!</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Log into the database from the terminal:&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;
    
    </summary>
    
    
      <category term="Postgres" scheme="http://ralucas.github.io/tags/Postgres/"/>
    
      <category term="CSV" scheme="http://ralucas.github.io/tags/CSV/"/>
    
  </entry>
  
  <entry>
    <title>Installing Postgres on Linux Mint</title>
    <link href="http://ralucas.github.io/2013/12/01/Installing-Postgres-on-Linux-Mint/"/>
    <id>http://ralucas.github.io/2013/12/01/Installing-Postgres-on-Linux-Mint/</id>
    <published>2013-12-02T01:10:59.000Z</published>
    <updated>2015-02-02T03:25:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>###A Quick Guide</p>
<h2 id=""><a href="#" class="headerlink" title=""></a><img src="http://t0.gstatic.com/images?q=tbn:ANd9GcSedctFKvhSpQSI7ZU3X5Xh91EPfEL3J4FP2j_MVksu_isCcDURqw" alt=""></h2><p>Open up the terminal:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sudo apt-get install postgresql</div></pre></td></tr></table></figure></p>
<p>Installs Postgresql.  This will take a few minutes.</p>
<p>Next:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sudo su - postgres</div></pre></td></tr></table></figure></p>
<p>This logs you into the database as the postgres user.  You will then want to create yourself as a user:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ createuser your_username</div></pre></td></tr></table></figure></p>
<p>Now, at the command prompt under your username, you are able to use createdb and other commands.  So, let’s create a quick database and connect to it.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ createdb myFirstDb</div></pre></td></tr></table></figure></p>
<p>Connect to it:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ psql myFirstDb</div></pre></td></tr></table></figure></p>
<p>You will then see a prompt that will look like:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">myFirstDb=#</div></pre></td></tr></table></figure></p>
<p>The <code>#</code> indicates that you are the superuser, which is most likely if you just installed postgres on your local computer.</p>
<p>Let’s run:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">myFirstDb=# SELECT Version();</div></pre></td></tr></table></figure></p>
<p>This should go into a new screen on your terminal that should look something like this:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">                                                version                                                </div><div class="line">-------------------------------------------------------------------------------------------------------</div><div class="line"> PostgreSQL 9.1.10 on i686-pc-linux-gnu, compiled by gcc (Ubuntu/Linaro 4.8.1-10ubuntu7) 4.8.1, 32-bit</div><div class="line">(1 row)</div><div class="line"></div><div class="line">(END)</div></pre></td></tr></table></figure></p>
<p>Type <code>q</code> to exit the screen and go back to the <code>#</code> prompt.</p>
<p>You can run commands from the <code>#</code> prompt using <code>\</code> notation and the official documentation on commands can be found here: <a href="http://www.postgresql.org/docs/9.3/interactive/app-psql.html" target="_blank" rel="external">http://www.postgresql.org/docs/9.3/interactive/app-psql.html</a></p>
<p>If you want a GUI client:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sudo apt-get install pgadmin3</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;###A Quick Guide&lt;/p&gt;
&lt;h2 id=&quot;&quot;&gt;&lt;a href=&quot;#&quot; class=&quot;headerlink&quot; title=&quot;&quot;&gt;&lt;/a&gt;&lt;img src=&quot;http://t0.gstatic.com/images?q=tbn:ANd9GcSedctFKvhSp
    
    </summary>
    
    
      <category term="Postgres" scheme="http://ralucas.github.io/tags/Postgres/"/>
    
      <category term="Linux Mint" scheme="http://ralucas.github.io/tags/Linux-Mint/"/>
    
  </entry>
  
  <entry>
    <title>Using Crockford&#39;s supplant function in Javascript</title>
    <link href="http://ralucas.github.io/2013/11/01/Using-Crockford-s-supplant-function-in-Javascript/"/>
    <id>http://ralucas.github.io/2013/11/01/Using-Crockford-s-supplant-function-in-Javascript/</id>
    <published>2013-11-02T00:09:07.000Z</published>
    <updated>2015-02-02T01:10:14.000Z</updated>
    
    <content type="html"><![CDATA[<p>The supplant function is easy to use for string interpolation and a nice introduction templating in JavaScript.</p>
<p>Here’s the function from <a href="http://javascript.crockford.com/remedial.html" target="_blank" rel="external">Douglas Crockford’s website</a>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">if (!String.prototype.supplant) &#123;</div><div class="line">  String.prototype.supplant = function (o) &#123;</div><div class="line">    return this.replace(/\&#123;([^&#123;&#125;]*)\&#125;/g,</div><div class="line">    function (a, b) &#123;</div><div class="line">      var r = o[b];</div><div class="line">      return typeof r === &apos;string&apos; || typeof r === &apos;number&apos; ? r : a;</div><div class="line">    &#125;);</div><div class="line">  &#125;;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>So how is it used.  Here’s a quick example:</p>
<p><code>var greeting = &quot;Hi, I&#39;m {name}&quot;.supplant[{name:&quot;Richard&quot;}];</code></p>
<p><em>Output: “Hi, I’m Richard”</em></p>
<p>Another example:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">myObj = &#123; </div><div class="line">  name: &apos;Richard&apos;,</div><div class="line">  city: &apos;Columbus&apos;,</div><div class="line">  state: &apos;Ohio&apos;</div><div class="line">  &#125;;</div><div class="line">  </div><div class="line">var myInfo = &quot;Hi, my name is &#123;name&#125; and I&apos;m from &#123;city&#125;, &#123;state&#125;&quot;.supplant(myObj);</div></pre></td></tr></table></figure>
<p><em>Output: “Hi, my name is Richard and I’m from Columbus, Ohio”</em></p>
<p>You can use it with arrays:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">var names = [&quot;Richard&quot;, &quot;Yalcin&quot;, &quot;Dan&quot;, &quot;Mike&quot;, &quot;Kerry&quot;];</div><div class="line"></div><div class="line">var classmates = &quot;My classmates are &#123;0&#125;, &#123;1&#125;, &#123;2&#125;, &#123;3&#125;, and &#123;4&#125;&quot;.supplant(names);</div></pre></td></tr></table></figure>
<p><em>Output: “My classmates are Richard, Yalcin, Dan, Mike, and Kerry”</em></p>
<p>These are a few examples, hopefully you do find them helpful. Supplant does take some criticism for being inefficient as well as unescapable, which are both founded. So, you may want to use supplant sparingly, but it’s certainly a great tool in learning JavaScript.</p>
<p>Here’s a <a href="http://stackoverflow.com/questions/1408289/best-way-to-do-variable-interpolation-in-javascript" target="_blank" rel="external">stack overflow post</a> that discusses it further as well.</p>
<p>And as you delve deeper into string interpolation and templating, I suggest looking into <a href="http://www.handlebarsjs.com" target="_blank" rel="external">Handlebars.js</a> or <a href="http://mustache.github.io/" target="_blank" rel="external">Mustache</a>.</p>
<p>As always, if you have any questions, please don’t hesitate to ask.</p>
<p>Cheers!</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;The supplant function is easy to use for string interpolation and a nice introduction templating in JavaScript.&lt;/p&gt;
&lt;p&gt;Here’s the functio
    
    </summary>
    
    
      <category term="JavaScript" scheme="http://ralucas.github.io/tags/JavaScript/"/>
    
      <category term="Supplant" scheme="http://ralucas.github.io/tags/Supplant/"/>
    
      <category term="Templating" scheme="http://ralucas.github.io/tags/Templating/"/>
    
  </entry>
  
  <entry>
    <title>Late Fragment by Raymond Carver</title>
    <link href="http://ralucas.github.io/2013/07/01/Late-Fragment-by-Raymond-Carver/"/>
    <id>http://ralucas.github.io/2013/07/01/Late-Fragment-by-Raymond-Carver/</id>
    <published>2013-07-02T00:05:36.000Z</published>
    <updated>2015-02-02T01:43:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>Great poem by one of my favorite writers.</p>
<blockquote>
<p>Late Fragment<br>by Raymond Carver</p>
<p>And did you get what<br>you wanted from this life, even so?<br>I did.<br>And what did you want?<br>To call myself beloved, to feel myself<br>beloved on the earth.</p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Great poem by one of my favorite writers.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Late Fragment&lt;br&gt;by Raymond Carver&lt;/p&gt;
&lt;p&gt;And did you get what&lt;br&gt;you wante
    
    </summary>
    
    
      <category term="Raymond Carver" scheme="http://ralucas.github.io/tags/Raymond-Carver/"/>
    
      <category term="Poem" scheme="http://ralucas.github.io/tags/Poem/"/>
    
  </entry>
  
  <entry>
    <title>Cleveland Marathon Race Report</title>
    <link href="http://ralucas.github.io/2013/06/01/Cleveland-Marathon-Race-Report/"/>
    <id>http://ralucas.github.io/2013/06/01/Cleveland-Marathon-Race-Report/</id>
    <published>2013-06-02T00:06:57.000Z</published>
    <updated>2015-02-02T03:25:42.000Z</updated>
    
    <content type="html"><![CDATA[<p>This past Sunday, I ran in the Cleveland Marathon.  I’d been training for the past 4-6 months for the race.  So, how did it go?  Well, I finished with a 3:43 time, so reasonably well.  I beat my goal time of 3:45 by a couple of minutes, so overall I’m quite happy with the results.</p>
<p>As I’ve mentioned earlier, I’ve been quite worried that my right foot was going to bother me the entire race, but after about 2 miles or so, it went away or I completely forgot about it.</p>
<p>####My race plan:</p>
<ol>
<li><p>Start out a little slow at a 9-minute pace for the first few miles and then begin to speed up.</p>
</li>
<li><p>Try to speed up in the second half of the race for a negative split.</p>
</li>
<li><p>Try to speed up after mile 16, in which the majority of the course would be heading down.</p>
</li>
</ol>
<p>For the most part I stuck to this plan.  I ran easy in the beginning and sped up a little, hitting the half marathon point at 1:50.  I then actually did speed up for the next split at 30K, doing a 8:17 split.  I was on pace and I was feeling great.  We were running through Rockefeller park, underneath the shade, and it was perfect.  But, then I started to slow up, particularly around mile 22.  This seemed to be the loneliest, hottest stretch of the race.  It was around I-90, there weren’t too many folks around, no shade and it was a long uphill.  That was a battle.  Between miles 21 and 25, I was really struggling.  My heart was working hard and I was really starting to feel it.  At the mile 23 water stop, I actually did stop to walk through it taking both a Powerade and water.  I walked for a minute or so, but knew I needed to get going.  Those couple of miles between 23 and 25, as I could see the downtown in the distance were tough miles.  I tried to gut it out, keeping a 9:15 pace going.  When I reached one mile to go, I tried to give it all I had and really got going up to speed with about a half mile to go.  And I made it with a good time.</p>
<p>####My nutrition plan:</p>
<ol>
<li><p>Clif Shot Blocks - eat one every two miles just before the water station and get some water to wash it down.</p>
</li>
<li><p>Then switch to the Honey Stingers - I broke these up and put them in a little ziplock bag.</p>
</li>
</ol>
<p>I stuck to the plan. I took one package (6 pieces) of the Shot Blocks, so for the first twelve miles I did that and then switched over to the Honey Stingers for the second half.  I think it worked for the most part as I didn’t have any noticeable sugar fall-outs in the race.  I think for the next race I’m just going to do two packages of the Shot Blocks as I was a little uncertain about how much of the Honey Stingers I was getting in.  The Shot Blocks are just nicely dosed, so they’re easier to manage.</p>
<p>My time and splits: <a href="http://live.xacte.com/cleveland/?id=110&amp;tagcode=1458" target="_blank" rel="external">http://live.xacte.com/cleveland/?id=110&amp;tagcode=1458</a></p>
<p>####Takeaways from the race:</p>
<ol>
<li>My training over the 4-6 months prior was worth all the work.</li>
<li>In particular, I really believe the weekly speed/interval training that I did was key for me maintaining my pace.</li>
<li>My nutrition was solid and I like the Clif Shots, so I think I may go to those only for a race.</li>
<li>There’s still some room for improvement and I’m going to move up my new goal to 3:30:<ul>
<li>I’m going to move my training pace up by 30 seconds to 9:30 pace.</li>
<li>I need to stay on track with my weekly speed work and look into potentially adding a second day per week of speed work.</li>
<li>I need to find a way to train myself better both physically and mentally for those difficult miles: 21-25.</li>
<li>Begin training for the 50-mile ultramarathon (My hypothesis is that by training for a longer race, I will be able to easily run a shorter one).</li>
<li>Take the VO2 Max test</li>
</ul>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;This past Sunday, I ran in the Cleveland Marathon.  I’d been training for the past 4-6 months for the race.  So, how did it go?  Well, I 
    
    </summary>
    
    
      <category term="Marathon" scheme="http://ralucas.github.io/tags/Marathon/"/>
    
      <category term="Cleveland" scheme="http://ralucas.github.io/tags/Cleveland/"/>
    
      <category term="Race Report" scheme="http://ralucas.github.io/tags/Race-Report/"/>
    
      <category term="Running" scheme="http://ralucas.github.io/tags/Running/"/>
    
  </entry>
  
  <entry>
    <title>How I&#39;ve trained for a marathon</title>
    <link href="http://ralucas.github.io/2013/06/01/How-I-ve-trained-for-a-marathon/"/>
    <id>http://ralucas.github.io/2013/06/01/How-I-ve-trained-for-a-marathon/</id>
    <published>2013-06-01T23:57:43.000Z</published>
    <updated>2015-02-02T01:07:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>I began really back in the summer of 2012, when I started training for the Columbus half-marathon and then the Whitney climb.  After I ran the half, I continued running, and in talking with a co-worker who had experience in marathoning, I began planning a winter marathon.  My initial plan was to run either the Jackson, MS or Baton Rouge/Louisiana Marathon, which were both taking place in January of 2013, I believe.</p>
<p>So, I found <a href="http://www.halhigdon.com/" target="_blank" rel="external">Hal Higdon’s site</a> and began following one of his plans. The site has plans for any level and a lot of great advice.  So, I started increasing my mileage, eventually doing a 22 mile run. This was all in November/December of 2012.  It was cold. I can remember doing the 22-mile run, not feeling super great upon embarkation, but doing it anyhow.  And I was only taking with me a water belt, with one gatorade and one water bottle, and a peanut butter and jelly sandwich.  Not enough really.  So, by the end of the run, I was dead tired, leg muscles cramping, and actually had to stop and walk and few times (really no big deal, but still not what I was hoping for). I was unprepared and probably pushed my body when I wasn’t feeling it.</p>
<p>During this time, I did decide to join a local running group, which began it’s ‘Winter Session’ in January.  This was fine as I was going to do a spring marathon anyways and my goal was (and still is) 3 marathons in 2013.  Joining the Marathoners-in-training group here in Columbus, for me, has been really great.  I’ve learned a ton about best training practices and regimens, proper nutrition, pacing, and I’ve met a bunch of kind, like-minded folks.</p>
<p>So, how I’ve trained:</p>
<ol>
<li><p>I started back in January for a May race, so 4 solid months, and I had some decent fitness already.  If you don’t, you may want to give yourself some more time and begin to build a stronger base.</p>
</li>
<li><p>My target pace is 8:30, which I think is doable, given my results in the half-marathon at a better pace (8:20).  Now that’s not significantly better than 8:30, but I’m hoping that given my training, I can hit it.  Prior to this January, I used to run at a much faster pace, 9-minute or faster.  Now all my runs are usually at around 10-minute pace as it was recommended that the rule of thumb for pacing is to run most of your practice runs at 60-90 seconds slower than your goal marathon pace.  One reason, I believe, for going a little slower is to build up your base.</p>
</li>
<li><p>I tried a variety of foods while running: Clif Shot Blocks, GU, Gatorade gels, Gummy Bears, Honey Stingers, Peanut Butter and Jelly Sandwich, Chews, Buddy Fruits, Powerbars, and any number of protein bars.  So, my favorites for running are the Clif Shot Blocks (usually Strawberry flavor) and the Honey Stingers.  The GU and Gummy bears did not sit well with me, and I think they’re just too much sugar, too quickly, even if I do try to offset with some water.  I could probably drink more water with them, but I just really like the shot blocks and stingers.</p>
</li>
<li><p>I’m still struggling on finding the right pair of shoes.  The primary reason is my feet are flat and so I overpronate.  I’ve been using/comparing the Asics Gel Kayano and the Nike Lunar Eclipse.  The real discovery for me has unfortunately come at the end of training, as now the ball of my right foot has begun to ache with the Metarsalgia I thought that I had gotten through.  You can read more about it <a href="http://rangeandroam.com/my-pain-in-the-ball-of-the-foot-from-running/" target="_blank" rel="external">here</a>.</p>
</li>
</ol>
<p>So, there you go.  Let me know if you have any suggestions or comments on how I could be doing this better.  Thanks.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I began really back in the summer of 2012, when I started training for the Columbus half-marathon and then the Whitney climb.  After I ra
    
    </summary>
    
    
      <category term="Marathon" scheme="http://ralucas.github.io/tags/Marathon/"/>
    
      <category term="Cleveland" scheme="http://ralucas.github.io/tags/Cleveland/"/>
    
      <category term="Running" scheme="http://ralucas.github.io/tags/Running/"/>
    
  </entry>
  
  <entry>
    <title>Running Pains</title>
    <link href="http://ralucas.github.io/2013/05/14/Running-Pains/"/>
    <id>http://ralucas.github.io/2013/05/14/Running-Pains/</id>
    <published>2013-05-14T18:00:00.000Z</published>
    <updated>2015-02-02T01:02:19.000Z</updated>
    
    <content type="html"><![CDATA[<p>I’m just going to preface this post by saying I’m not a doctor, so this is simply my own experience.  If you’re feeling foot pain you should see a doctor.</p>
<p>So, over the past year or so, since I’ve really started running in earnest and outside a lot more, I’ve developed an intermittent pain in the ball of my foot.  Last year, it was on my left foot, but now it has migrated to my right foot.  When it happened last year, I got worried that maybe it was a stress fracture, so I went to the podiatrist right away.  He gave the foot an X-ray and it wasn’t fractured.  He told me, he thought it was a neuroma or metatarsalgia.  And suggested, given my flat feet, I really should get custom orthotics.  I still haven’t done that.</p>
<p>Nonetheless, I took some time off, began running more, and the pain really ended up going away.  It didn’t come back until I decided, being the smart guy that I am, that I needed to break in a new pair of running shoes for the upcoming marathon.  And so on about the 3rd or 4th run, I started getting that dull, ball of the foot pain around the 2nd and 3rd toe.  A real bummer.  And now as I’m getting ready to run here this coming Sunday, my foot is still bothering a bit.  Hopefully, I’ll be fine for most of the race and I’m going to just tough it out if it does bother me.  It’s really not bad, just sort of a bothersome ache/pain.</p>
<p>Here’s what I’ve learned, but don’t hold me to this:</p>
<ol>
<li><p>Need to make sure the toe box in the shoe is good and roomy.  I’m going to try a new tying method.</p>
</li>
<li><p>A new pair of shoes can potentially cause re-inflammation.  Don’t break in a pair of shoes with a month to go in training.  I actually thought I’d be fine.  Lesson learned.  Start out with a couple (or more) pairs.</p>
</li>
<li><p>I probably should have done a bit more cross-training near the end when my foot was bothering me and I’m going to try that this summer, should it happen again.</p>
</li>
</ol>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;I’m just going to preface this post by saying I’m not a doctor, so this is simply my own experience.  If you’re feeling foot pain you sho
    
    </summary>
    
    
      <category term="Running" scheme="http://ralucas.github.io/tags/Running/"/>
    
      <category term="Injury" scheme="http://ralucas.github.io/tags/Injury/"/>
    
  </entry>
  
  <entry>
    <title>Tough Mudder Review</title>
    <link href="http://ralucas.github.io/2013/05/01/Tough-Mudder-Review/"/>
    <id>http://ralucas.github.io/2013/05/01/Tough-Mudder-Review/</id>
    <published>2013-05-01T23:46:15.000Z</published>
    <updated>2015-02-02T03:24:57.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="//res.cloudinary.com/dgfchlycf/image/upload/v1385447221/262292_10151580137014630_246172225_n_uxcfmr.jpg" alt="The Tough Mudder Group"></p>
<p>So, I did the Tough Mudder here in Ohio this past Saturday with my sister and a couple of people that joined our team after I put up forum post for team members.  It was held in Mansfield, OH about an hour north of Columbus.</p>
<p>My sister and I signed up for it, not really knowing much about it, back in the fall of last year.  I had heard a friend mention it and I thought that it sounded like a good challenge.  It costs us, I believe, around $120 to do the event.</p>
<p>The Tough Mudder is basically an obstacles course with muddy terrain and is part of the growing phenomenon of these obstacle-type runs that seem to be popping up everywhere.  It took place at what seemed to be a farm near Mansfield, Ohio. It’s a ten mile course and they had 22 obstacles.  They range from crawling under barb wire for 15 feet to climbing over walls that are 15 feet to just running/walking through a muddy path.  Some of the obstacles can be a bit tough, particularly as the day wears on.</p>
<p>My sister and I signed up, but we needed to get more team members.  Unfortunately, we couldn’t convince any of our friends to join us, so we put up a post on the forums and Adriana and Bob responded to join our team.  We really couldn’t have asked for better teammates.  They were great.</p>
<p>Okay, so we trained and then finally came the day of the event.  The emails from the organization told us to try to arrive 2 hours earlier than your start time.  Being an unbeliever in showing up too early for anything, we blew that off and decided to show up an hour early.  Well, we should have listened to them.  There was a huge crowd, traffic, parking lines, and then we got bussed to the race field.  We estimated that if they had about 9,000 participants per day going through the course.  That’s quite a bit. We ended up arriving about 40 minutes late.  So, we should have taken that 2 hours prior a bit more seriously.</p>
<p>We really lucked out, though: it was a beautiful day - mid-60s and sunny. Upon arriving, we located Bob and Adriana and jetted off to start of the race. Before beginning, the MC gave a 20 minute speech, trying to rile everyone up, going over the standards and rules, and of course, not forgetting to mention all of the corporate sponsors.  And then finally, we were off.</p>
<p>The total time we spent out on the course was about 4-1/2 hours, which is basically the equivalent of a marathon time-wise.  For the most part, we tried to run/jog between the obstacles, giving into a walk when the mud became particularly heavy.  And the mud was heavy for the most part and it was everywhere.  Tying your shoes on tight is essential if you want to keep them on.</p>
<p>Bob was the only team member to have successfully completed all the obstacles.  I felt like I did fairly well, only being unable to get past the monkey bars (my excuse: hands were too wet and slipped). Adriana completed the monkey bars successfully and was told that she was one of the few women to have accomplished that. And my sister had a lot of success and attempted every obstacle.</p>
<p><strong>Toughest obstacle:</strong> Berlin Walls - Part of the reason was that I initially attempted this solo and didn’t make it.  Fortunately some fellows helped me over, but it was still rough pulling myself over the walls.</p>
<p>As we neared the last 5 or 6 obstacles, lines began to grow and getting through the obstacles began to take more and more time.  This was a bit of a detractor and I thought that perhaps they should begin to limit the amount of people on the course per day as it really seemed like too many.</p>
<p>I will say this, I was sore for about two days after it and even now have large bruises under my arms from lifting myself up on the walls.</p>
<p>In terms of training, the Tough Mudder website has some training suggestions, but I didn’t really attempt them. I felt that they were too difficult and crazy to attempt at the gym.  My training was basically train for a marathon and I also did some weightlifting, swimming, and some of the DVD Insanity.  So, I would do a workout of either weights, swim, or DVD in the morning and then do my mileage of running in the evenings.  This is probably more than most people would have time to do, so I think that if you’re just maintaining a healthy running schedule with some weight training thrown in there, you would be fine and no need to workout twice a day, either.</p>
<p>My conclusion: We had a fun time out there, got great weather, and met a couple of good folks.  I don’t think I would do it again because, well, I guess I don’t see what the big deal about it is.  Surely, it taxed me physically, but I didn’t feel like it was truly an intense physical experience.  Certain obstacles were difficult, but the majority of them were very reasonable for anyone in decent shape to complete.  If I was more flexible, the wall climbing may have been easier.  I think, for myself, I didn’t really get that feeling of accomplishment and perhaps this was because I’ve had my sights on the completion of an upcoming marathon and then some mountain hiking.</p>
<p><img src="//res.cloudinary.com/dgfchlycf/image/upload/v1385447227/943123_10151580136954630_1928244936_n_cexmv2.jpg" alt="Hooray!"></p>
<p>My recommendation would be, definitely do it if you feel like this would be something that you would enjoy and you’ve got a good group to do it with, but if you’re doing it to prove something to yourself, I think there are more difficult physical challenges out there.  Thanks for reading this.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;//res.cloudinary.com/dgfchlycf/image/upload/v1385447221/262292_10151580137014630_246172225_n_uxcfmr.jpg&quot; alt=&quot;The Tough Mudder 
    
    </summary>
    
    
      <category term="Running" scheme="http://ralucas.github.io/tags/Running/"/>
    
      <category term="Tough Mudder" scheme="http://ralucas.github.io/tags/Tough-Mudder/"/>
    
  </entry>
  
</feed>
